<!DOCTYPE html><html class="client-nojs" lang="en" dir="ltr"><head><meta charset="UTF-8"/><title>Vector processor - Wikipedia</title><script>document.documentElement.className="client-js";RLCONF={"wgBreakFrames":!1,"wgSeparatorTransformTable":["",""],"wgDigitTransformTable":["",""],"wgDefaultDateFormat":"dmy","wgMonthNames":["","January","February","March","April","May","June","July","August","September","October","November","December"],"wgRequestId":"bdcf6a3c-3eaf-4591-85a3-9724624728f4","wgCSPNonce":!1,"wgCanonicalNamespace":"","wgCanonicalSpecialPageName":!1,"wgNamespaceNumber":0,"wgPageName":"Vector_processor","wgTitle":"Vector processor","wgCurRevisionId":991699793,"wgRevisionId":991699793,"wgArticleId":58205,"wgIsArticle":!0,"wgIsRedirect":!1,"wgAction":"view","wgUserName":null,"wgUserGroups":["*"],"wgCategories":["Articles containing potentially dated statements from 2016","All articles containing potentially dated statements","Central processing unit","Coprocessors","Parallel computing","Vector supercomputers"],"wgPageContentLanguage":"en","wgPageContentModel":"wikitext","wgRelevantPageName":"Vector_processor","wgRelevantArticleId":58205,"wgIsProbablyEditable":!0,"wgRelevantPageIsProbablyEditable":!0,"wgRestrictionEdit":[],"wgRestrictionMove":[],"wgMediaViewerOnClick":!0,"wgMediaViewerEnabledByDefault":!0,"wgPopupsReferencePreviews":!1,"wgPopupsConflictsWithNavPopupGadget":!1,"wgVisualEditor":{"pageLanguageCode":"en","pageLanguageDir":"ltr","pageVariantFallbacks":"en"},"wgMFDisplayWikibaseDescriptions":{"search":!0,"nearby":!0,"watchlist":!0,"tagline":!1},"wgWMESchemaEditAttemptStepOversample":!1,"wgULSCurrentAutonym":"English","wgNoticeProject":"wikipedia","wgCentralAuthMobileDomain":!1,"wgEditSubmitButtonLabelPublish":!0,"wgULSPosition":"interlanguage","wgWikibaseItemId":"Q919509"};RLSTATE={"ext.globalCssJs.user.styles":"ready","site.styles":"ready","noscript":"ready","user.styles":"ready","ext.globalCssJs.user":"ready","user":"ready","user.options":"loading","ext.cite.styles":"ready","ext.pygments":"ready","ext.math.styles":"ready","skins.vector.styles.legacy":"ready","jquery.makeCollapsible.styles":"ready","ext.visualEditor.desktopArticleTarget.noscript":"ready","ext.uls.interlanguage":"ready","ext.wikimediaBadges":"ready","wikibase.client.init":"ready"};RLPAGEMODULES=["ext.cite.ux-enhancements","ext.math.scripts","site","mediawiki.page.ready","jquery.makeCollapsible","mediawiki.toc","skins.vector.legacy.js","ext.gadget.ReferenceTooltips","ext.gadget.charinsert","ext.gadget.extra-toolbar-buttons","ext.gadget.refToolbar","ext.gadget.switcher","ext.centralauth.centralautologin","mmv.head","mmv.bootstrap.autostart","ext.popups","ext.visualEditor.desktopArticleTarget.init","ext.visualEditor.targetLoader","ext.eventLogging","ext.wikimediaEvents","ext.navigationTiming","ext.uls.compactlinks","ext.uls.interface","ext.cx.eventlogging.campaigns","ext.quicksurveys.init","ext.centralNotice.geoIP","ext.centralNotice.startUp"];</script><script>(RLQ=window.RLQ||[]).push(function(){mw.loader.implement("user.options@1hzgi",function($,jQuery,require,module){/*@nomin*/mw.user.tokens.set({"patrolToken":"+\\","watchToken":"+\\","csrfToken":"+\\"});});});</script><link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.math.styles%7Cext.pygments%2CwikimediaBadges%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cjquery.makeCollapsible.styles%7Cskins.vector.styles.legacy%7Cwikibase.client.init&amp;only=styles&amp;skin=vector"/><script async="" src="/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector"></script><meta name="ResourceLoaderDynamicStyles" content=""/><link rel="stylesheet" href="/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector"/><meta name="generator" content="MediaWiki 1.36.0-wmf.18"/><meta name="referrer" content="origin"/><meta name="referrer" content="origin-when-crossorigin"/><meta name="referrer" content="origin-when-cross-origin"/><link rel="preconnect" href="//upload.wikimedia.org"/><link rel="alternate" media="only screen and (max-width: 720px)" href="//en.m.wikipedia.org/wiki/Vector_processor"/><link rel="alternate" type="application/x-wiki" title="Edit this page" href="/w/index.php?title=Vector_processor&amp;action=edit"/><link rel="edit" title="Edit this page" href="/w/index.php?title=Vector_processor&amp;action=edit"/><link rel="apple-touch-icon" href="/static/apple-touch/wikipedia.png"/><link rel="shortcut icon" href="/static/favicon/wikipedia.ico"/><link rel="search" type="application/opensearchdescription+xml" href="/w/opensearch_desc.php" title="Wikipedia (en)"/><link rel="EditURI" type="application/rsd+xml" href="//en.wikipedia.org/w/api.php?action=rsd"/><link rel="license" href="//creativecommons.org/licenses/by-sa/3.0/"/><link rel="canonical" href="https://en.wikipedia.org/wiki/Vector_processor"/><link rel="dns-prefetch" href="//login.wikimedia.org"/><link rel="dns-prefetch" href="//meta.wikimedia.org" /></head><body class="mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Vector_processor rootpage-Vector_processor skin-vector action-view skin-vector-legacy"><div id="mw-page-base" class="noprint"></div><div id="mw-head-base" class="noprint"></div><div id="content" class="mw-body" role="main">	<a id="top"></a>	<div id="siteNotice" class="mw-body-content"><!-- CentralNotice --></div>	<div class="mw-indicators mw-body-content">	</div>	<h1 id="firstHeading" class="firstHeading" lang="en">Vector processor</h1>	<div id="bodyContent" class="mw-body-content">		<div id="siteSub" class="noprint">From Wikipedia, the free encyclopedia</div>		<div id="contentSub"></div>		<div id="contentSub2"></div>				<div id="jump-to-nav"></div>		<a class="mw-jump-link" href="#mw-head">Jump to navigation</a>		<a class="mw-jump-link" href="#searchInput">Jump to search</a>		<div id="mw-content-text" lang="en" dir="ltr" class="mw-content-ltr"><div class="mw-parser-output"><div role="note" class="hatnote navigation-not-searchable">"Array processor" redirects here. It is not to be confused with <a href="/wiki/Array_processing" title="Array processing">Array processing</a>.</div><p>In <a href="/wiki/Computing" title="Computing">computing</a>, a <b>vector processor</b> or <b>array processor</b> is a <a href="/wiki/Central_processing_unit" title="Central processing unit">central processing unit</a> (CPU) that implements an <a href="/wiki/Instruction_set" class="mw-redirect" title="Instruction set">instruction set</a> containing <a href="/wiki/Instruction_(computer_science)" class="mw-redirect" title="Instruction (computer science)">instructions</a> that operate on <a href="/wiki/Array_data_structure" title="Array data structure">one-dimensional arrays</a> of data called <i>vectors</i>, compared to the <a href="/wiki/Scalar_processor" title="Scalar processor">scalar processors</a>, whose instructions operate on single data items. Vector processors can greatly improve performance on certain workloads, notably <a href="/wiki/Numerical_simulation" class="mw-redirect" title="Numerical simulation">numerical simulation</a> and similar tasks. Vector machines appeared in the early 1970s and dominated <a href="/wiki/Supercomputer" title="Supercomputer">supercomputer</a> design through the 1970s into the 1990s, notably the various <a href="/wiki/Cray" title="Cray">Cray</a> platforms. The rapid fall in the <a href="/wiki/Price-to-performance_ratio" class="mw-redirect" title="Price-to-performance ratio">price-to-performance ratio</a> of conventional <a href="/wiki/Microprocessor" title="Microprocessor">microprocessor</a> designs led to the vector supercomputer's demise in the later 1990s.</p><p>As of 2016<sup class="plainlinks noexcerpt noprint asof-tag update" style="display:none;"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Vector_processor&amp;action=edit">&#91;update&#93;</a></sup> most commodity CPUs implement architectures that feature <a href="/wiki/SIMD" title="SIMD">SIMD</a> instructions for a form of vector processing on multiple (vectorized) data sets. Common examples include Intel x86's <a href="/wiki/MMX_(instruction_set)" title="MMX (instruction set)">MMX</a>, <a href="/wiki/Streaming_SIMD_Extensions" title="Streaming SIMD Extensions">SSE</a> and <a href="/wiki/Advanced_Vector_Extensions" title="Advanced Vector Extensions">AVX</a> instructions, AMD's <a href="/wiki/3DNow!" title="3DNow!">3DNow!</a> extensions, Sparc's <a href="/wiki/Visual_Instruction_Set" title="Visual Instruction Set">VIS</a> extension, <a href="/wiki/PowerPC" title="PowerPC">PowerPC</a>'s <a href="/wiki/AltiVec" title="AltiVec">AltiVec</a> and MIPS' <a href="/w/index.php?title=MIPS_SIMD_Architecture&amp;action=edit&amp;redlink=1" class="new" title="MIPS SIMD Architecture (page does not exist)">MSA</a>. Vector processing techniques also operate in <a href="/wiki/Video_game_console" title="Video game console">video-game console</a> hardware and in <a href="/wiki/Graphics_accelerator" class="mw-redirect" title="Graphics accelerator">graphics accelerators</a>. In 2000, <a href="/wiki/IBM" title="IBM">IBM</a>, <a href="/wiki/Toshiba" title="Toshiba">Toshiba</a> and <a href="/wiki/Sony" title="Sony">Sony</a> collaborated to create the <a href="/wiki/Cell_(microprocessor)" title="Cell (microprocessor)">Cell processor</a>.</p><p>Other CPU designs include some multiple instructions for vector processing on multiple (vectorised) data sets, typically known as <a href="/wiki/MIMD" title="MIMD">MIMD</a> (<b>M</b>ultiple <b>I</b>nstruction, <b>M</b>ultiple <b>D</b>ata) and realized with <a href="/wiki/VLIW" class="mw-redirect" title="VLIW">VLIW</a> (<b>V</b>ery <b>L</b>ong <b>I</b>nstruction <b>W</b>ord). The <a href="/wiki/Fujitsu" title="Fujitsu">Fujitsu</a> <a href="/wiki/FR-V" class="mw-redirect" title="FR-V">FR-V</a> VLIW/<i>vector processor</i> combines both technologies.</p><div id="toc" class="toc" role="navigation" aria-labelledby="mw-toc-heading"><input type="checkbox" role="button" id="toctogglecheckbox" class="toctogglecheckbox" style="display:none" /><div class="toctitle" lang="en" dir="ltr"><h2 id="mw-toc-heading">Contents</h2><span class="toctogglespan"><label class="toctogglelabel" for="toctogglecheckbox"></label></span></div><ul><li class="toclevel-1 tocsection-1"><a href="#History"><span class="tocnumber">1</span> <span class="toctext">History</span></a><ul><li class="toclevel-2 tocsection-2"><a href="#Early_work"><span class="tocnumber">1.1</span> <span class="toctext">Early work</span></a></li><li class="toclevel-2 tocsection-3"><a href="#Supercomputers"><span class="tocnumber">1.2</span> <span class="toctext">Supercomputers</span></a></li><li class="toclevel-2 tocsection-4"><a href="#GPU"><span class="tocnumber">1.3</span> <span class="toctext">GPU</span></a></li></ul></li><li class="toclevel-1 tocsection-5"><a href="#Description"><span class="tocnumber">2</span> <span class="toctext">Description</span></a><ul><li class="toclevel-2 tocsection-6"><a href="#Vector_instructions"><span class="tocnumber">2.1</span> <span class="toctext">Vector instructions</span></a></li></ul></li><li class="toclevel-1 tocsection-7"><a href="#Performance_and_speed_up"><span class="tocnumber">3</span> <span class="toctext">Performance and speed up</span></a></li><li class="toclevel-1 tocsection-8"><a href="#Programming_heterogeneous_computing_architectures"><span class="tocnumber">4</span> <span class="toctext">Programming heterogeneous computing architectures</span></a></li><li class="toclevel-1 tocsection-9"><a href="#See_also"><span class="tocnumber">5</span> <span class="toctext">See also</span></a></li><li class="toclevel-1 tocsection-10"><a href="#References"><span class="tocnumber">6</span> <span class="toctext">References</span></a></li><li class="toclevel-1 tocsection-11"><a href="#External_links"><span class="tocnumber">7</span> <span class="toctext">External links</span></a></li></ul></div><h2><span class="mw-headline" id="History">History</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Vector_processor&amp;action=edit&amp;section=1" title="Edit section: History">edit</a><span class="mw-editsection-bracket">]</span></span></h2><h3><span class="mw-headline" id="Early_work">Early work</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Vector_processor&amp;action=edit&amp;section=2" title="Edit section: Early work">edit</a><span class="mw-editsection-bracket">]</span></span></h3><p>Vector processing development began in the early 1960s at <a href="/wiki/Westinghouse_Electric_Corporation" title="Westinghouse Electric Corporation">Westinghouse</a> in their "Solomon" project. Solomon's goal was to dramatically increase math performance by using a large number of simple <a href="/wiki/Coprocessor" title="Coprocessor">math co-processors</a> under the control of a single master <a href="/wiki/Central_processing_unit" title="Central processing unit">CPU</a>. The CPU fed a single common instruction to all of the <a href="/wiki/Arithmetic_logic_unit" title="Arithmetic logic unit">arithmetic logic units</a> (ALUs), one per cycle, but with a different data point for each one to work on. This allowed the Solomon machine to apply a single <a href="/wiki/Algorithm" title="Algorithm">algorithm</a> to a large <a href="/wiki/Data_set" title="Data set">data set</a>, fed in the form of an array.</p><p>In 1962, Westinghouse cancelled the project, but the effort was restarted at the <a href="/wiki/University_of_Illinois_at_Urbana%E2%80%93Champaign" title="University of Illinois at Urbana–Champaign">University of Illinois</a> as the <a href="/wiki/ILLIAC_IV" title="ILLIAC IV">ILLIAC IV</a>. Their version of the design originally called for a 1 <a href="/wiki/GFLOPS" class="mw-redirect" title="GFLOPS">GFLOPS</a> machine with 256 ALUs, but, when it was finally delivered in 1972, it had only 64 ALUs and could reach only 100 to 150 MFLOPS. Nevertheless, it showed that the basic concept was sound, and, when used on data-intensive applications, such as <a href="/wiki/Computational_fluid_dynamics" title="Computational fluid dynamics">computational fluid dynamics</a>, the ILLIAC was the fastest machine in the world. The ILLIAC approach of using separate ALUs for each data element is not common to later designs, and is often referred to under a separate category, <a href="/wiki/Massively_parallel" title="Massively parallel">massively parallel</a> computing.</p><p>A <a href="/wiki/Computer_for_operations_with_functions" title="Computer for operations with functions">computer for operations with functions</a> was presented and developed by Kartsev in 1967.<sup id="cite_ref-Malinovsky_1-0" class="reference"><a href="#cite_note-Malinovsky-1">&#91;1&#93;</a></sup></p><h3><span class="mw-headline" id="Supercomputers">Supercomputers</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Vector_processor&amp;action=edit&amp;section=3" title="Edit section: Supercomputers">edit</a><span class="mw-editsection-bracket">]</span></span></h3><p>The first successful implementation of vector processing occurred in 1966, when both the <a href="/wiki/Control_Data_Corporation" title="Control Data Corporation">Control Data Corporation</a> <a href="/wiki/CDC_STAR-100" title="CDC STAR-100">STAR-100</a> and the <a href="/wiki/Texas_Instruments" title="Texas Instruments">Texas Instruments</a> <a href="/wiki/Advanced_Scientific_Computer" class="mw-redirect" title="Advanced Scientific Computer">Advanced Scientific Computer</a> (ASC) were introduced.</p><p>The basic ASC (i.e., "one pipe") ALU used a pipeline architecture that supported both scalar and vector computations, with peak performance reaching approximately 20 MFLOPS, readily achieved when processing long vectors. Expanded ALU configurations supported "two pipes" or "four pipes" with a corresponding 2X or 4X performance gain. Memory bandwidth was sufficient to support these expanded modes.</p><p>The STAR was otherwise slower than CDC's own supercomputers like the <a href="/wiki/CDC_7600" title="CDC 7600">CDC 7600</a>, but at data related tasks they could keep up while being much smaller and less expensive. However the machine also took considerable time decoding the vector instructions and getting ready to run the process, so it required very specific data sets to work on before it actually sped anything up.</p><p>The vector technique was first fully exploited in 1976 by the famous <a href="/wiki/Cray-1" title="Cray-1">Cray-1</a>. Instead of leaving the data in memory like the STAR and ASC, the Cray design had eight <a href="/wiki/Vector_registers" class="mw-redirect" title="Vector registers">vector registers</a>, which held sixty-four 64-bit words each. The vector instructions were applied between registers, which is much faster than talking to main memory. Whereas the STAR would apply a single operation across a long vector in memory and then move on to the next operation, the Cray design would load a smaller section of the vector into registers and then apply as many operations as it could to that data, thereby avoiding many of the much slower memory access operations.</p><p>The Cray design used <a href="/wiki/Pipeline_parallelism" class="mw-redirect" title="Pipeline parallelism">pipeline parallelism</a> to implement vector instructions rather than multiple ALUs. In addition, the design had completely separate pipelines for different instructions, for example, addition/subtraction was implemented in different hardware than multiplication. This allowed a batch of vector instructions to be pipelined into each of the ALU subunits, a technique they called <i>vector chaining</i>. The Cray-1 normally had a performance of about 80 MFLOPS, but with up to three chains running it could peak at 240&#160;MFLOPS and averaged around 150 – far faster than any machine of the era.</p><div class="thumb tright"><div class="thumbinner" style="width:222px;"><a href="/wiki/File:Cray_J90_CPU_module.jpg" class="image"><img alt="" src="//upload.wikimedia.org/wikipedia/commons/thumb/9/9b/Cray_J90_CPU_module.jpg/220px-Cray_J90_CPU_module.jpg" decoding="async" width="220" height="165" class="thumbimage" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/9/9b/Cray_J90_CPU_module.jpg/330px-Cray_J90_CPU_module.jpg 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/9/9b/Cray_J90_CPU_module.jpg/440px-Cray_J90_CPU_module.jpg 2x" data-file-width="720" data-file-height="540" /></a>  <div class="thumbcaption"><div class="magnify"><a href="/wiki/File:Cray_J90_CPU_module.jpg" class="internal" title="Enlarge"></a></div><a href="/wiki/Cray_J90" title="Cray J90">Cray J90</a> processor module with four scalar/vector processors</div></div></div><p>Other examples followed. <a href="/wiki/Control_Data_Corporation" title="Control Data Corporation">Control Data Corporation</a> tried to re-enter the high-end market again with its <a href="/wiki/ETA-10" class="mw-redirect" title="ETA-10">ETA-10</a> machine, but it sold poorly and they took that as an opportunity to leave the supercomputing field entirely. In the early and mid-1980s Japanese companies (<a href="/wiki/Fujitsu" title="Fujitsu">Fujitsu</a>, <a href="/wiki/Hitachi,_Ltd." class="mw-redirect" title="Hitachi, Ltd.">Hitachi</a> and <a href="/wiki/Nippon_Electric_Corporation" class="mw-redirect" title="Nippon Electric Corporation">Nippon Electric Corporation</a> (NEC) introduced register-based vector machines similar to the Cray-1, typically being slightly faster and much smaller. <a href="/wiki/Oregon" title="Oregon">Oregon</a>-based <a href="/wiki/Floating_Point_Systems" title="Floating Point Systems">Floating Point Systems</a> (FPS) built add-on array processors for <a href="/wiki/Minicomputer" title="Minicomputer">minicomputers</a>, later building their own <a href="/wiki/Minisupercomputer" title="Minisupercomputer">minisupercomputers</a>.</p><p>Throughout, Cray continued to be the performance leader, continually beating the competition with a series of machines that led to the <a href="/wiki/Cray-2" title="Cray-2">Cray-2</a>, <a href="/wiki/Cray_X-MP" title="Cray X-MP">Cray X-MP</a> and <a href="/wiki/Cray_Y-MP" title="Cray Y-MP">Cray Y-MP</a>. Since then, the supercomputer market has focused much more on <a href="/wiki/Massively_parallel" title="Massively parallel">massively parallel</a> processing rather than better implementations of vector processors. However, recognising the benefits of vector processing IBM developed <a href="/wiki/IBM_ViVA" title="IBM ViVA">Virtual Vector Architecture</a> for use in supercomputers coupling several scalar processors to act as a vector processor.</p><p>Although vector supercomputers resembling the Cray-1 are less popular these days, NEC has continued to make this type of computer up to the present day with their <a href="/wiki/NEC_SX_architecture" class="mw-redirect" title="NEC SX architecture">SX series</a> of computers. Most recently, the <a href="/wiki/SX-Aurora_TSUBASA" class="mw-redirect" title="SX-Aurora TSUBASA">SX-Aurora TSUBASA</a> places the processor and either 24 or 48 gigabytes of memory on an <a href="/wiki/High_Bandwidth_Memory" title="High Bandwidth Memory">HBM</a> 2 module within a card that physically resembles a graphics coprocessor, but instead of serving as a co-processor, it is the main computer with the PC-compatible computer into which it is plugged serving support functions.</p><h3><span class="mw-headline" id="GPU">GPU</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Vector_processor&amp;action=edit&amp;section=4" title="Edit section: GPU">edit</a><span class="mw-editsection-bracket">]</span></span></h3><div role="note" class="hatnote navigation-not-searchable">Main article: <a href="/wiki/Single_instruction,_multiple_threads" title="Single instruction, multiple threads">Single instruction, multiple threads</a></div><p>Modern graphics processing units (<a href="/wiki/GPUs" class="mw-redirect" title="GPUs">GPUs</a>) include an array of shader pipelines which may be driven by <a href="/wiki/Compute_kernel" title="Compute kernel">compute kernels</a>, which can be considered vector processors (using a similar strategy for hiding memory latencies).</p><h2><span class="mw-headline" id="Description">Description</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Vector_processor&amp;action=edit&amp;section=5" title="Edit section: Description">edit</a><span class="mw-editsection-bracket">]</span></span></h2><p>In general terms, CPUs are able to manipulate one or two pieces of data at a time. For instance, most CPUs have an instruction that essentially says "add A to B and put the result in C". The data for A, B and C could be—in theory at least—encoded directly into the instruction. However, in efficient implementation things are rarely that simple. The data is rarely sent in raw form, and is instead "pointed to" by passing in an address to a memory location that holds the data. Decoding this address and getting the data out of the memory takes some time, during which the CPU traditionally would sit idle waiting for the requested data to show up.  As CPU speeds have increased, this <i><a href="/wiki/Memory_latency" title="Memory latency">memory latency</a></i> has historically become a large impediment to performance; see <a href="/wiki/Random-access_memory#Memory_wall" title="Random-access memory">Memory wall</a>.</p><p>In order to reduce the amount of time consumed by these steps, most modern CPUs use a technique known as <a href="/wiki/Instruction_pipelining" title="Instruction pipelining">instruction pipelining</a> in which the instructions pass through several sub-units in turn. The first sub-unit reads the address and decodes it, the next "fetches" the values at those addresses, and the next does the math itself. With pipelining the "trick" is to start decoding the next instruction even before the first has left the CPU, in the fashion of an <a href="/wiki/Assembly_line" title="Assembly line">assembly line</a>, so the <a href="/wiki/Address_decoder" title="Address decoder">address decoder</a> is constantly in use.  Any particular instruction takes the same amount of time to complete, a time known as the <i><a href="/wiki/Latency_(engineering)" title="Latency (engineering)">latency</a></i>, but the CPU can process an entire batch of operations much faster and more efficiently than if it did so one at a time.</p><p>Vector processors take this concept one step further. Instead of pipelining just the instructions, they also pipeline the data itself. The processor is fed instructions that say not just to add A to B, but to add all of the numbers "from here to here" to all of the numbers "from there to there". Instead of constantly having to decode instructions and then fetch the data needed to complete them, the processor reads a single instruction from memory, and it is simply implied in the definition of the instruction <i>itself</i> that the instruction will operate again on another item of data, at an address one increment larger than the last. This allows for significant savings in decoding time.</p><p>To illustrate what a difference this can make, consider the simple task of adding two groups of 10 numbers together. In a normal programming language one would write a "loop" that picked up each of the pairs of numbers in turn, and then added them. To the CPU, this would look something like this:</p><div class="mw-highlight mw-highlight-lang-gas mw-content-ltr" dir="ltr"><pre><span></span><span class="c">; Hypothetical RISC machine</span><span class="c">; add 10 numbers in a to 10 numbers in b, storing results in c</span><span class="c">; assume a, b, and c are memory locations in their respective registers</span>  <span class="nf">move</span>  <span class="no">$10</span><span class="p">,</span> <span class="no">count</span>   <span class="c">; count&#160;:= 10</span><span class="nl">loop:</span>  <span class="nf">load</span>  <span class="no">r1</span><span class="p">,</span> <span class="no">a</span>  <span class="nf">load</span>  <span class="no">r2</span><span class="p">,</span> <span class="no">b</span>  <span class="nf">add</span>   <span class="no">r3</span><span class="p">,</span> <span class="no">r1</span><span class="p">,</span> <span class="no">r2</span>   <span class="c">; r3&#160;:= r1 + r2</span>  <span class="nf">store</span> <span class="no">r3</span><span class="p">,</span> <span class="no">c</span>  <span class="nf">add</span>   <span class="no">a</span><span class="p">,</span> <span class="no">a</span><span class="p">,</span> <span class="no">$4</span>     <span class="c">; move on</span>  <span class="nf">add</span>   <span class="no">b</span><span class="p">,</span> <span class="no">b</span><span class="p">,</span> <span class="no">$4</span>  <span class="nf">add</span>   <span class="no">c</span><span class="p">,</span> <span class="no">c</span><span class="p">,</span> <span class="no">$4</span>  <span class="nf">dec</span>   <span class="no">count</span>        <span class="c">; decrement</span>  <span class="nf">jnez</span>  <span class="no">count</span><span class="p">,</span> <span class="no">loop</span>  <span class="c">; loop back if count is not yet 0</span>  <span class="nf">ret</span></pre></div><p>But to a vector processor, this task looks considerably different:</p><div class="mw-highlight mw-highlight-lang-gas mw-content-ltr" dir="ltr"><pre><span></span><span class="c">; assume we have vector registers v1-v3 with size larger than 10</span>  <span class="nf">move</span>   <span class="no">$10</span><span class="p">,</span> <span class="no">count</span>    <span class="c">; count = 10</span>  <span class="nf">vload</span>  <span class="no">v1</span><span class="p">,</span> <span class="no">a</span><span class="p">,</span> <span class="no">count</span>  <span class="nf">vload</span>  <span class="no">v2</span><span class="p">,</span> <span class="no">b</span><span class="p">,</span> <span class="no">count</span>  <span class="nf">vadd</span>   <span class="no">v3</span><span class="p">,</span> <span class="no">v1</span><span class="p">,</span> <span class="no">v2</span>  <span class="nf">vstore</span> <span class="no">v3</span><span class="p">,</span> <span class="no">c</span><span class="p">,</span> <span class="no">count</span>  <span class="nf">ret</span></pre></div><p>There are several savings inherent in this approach. For one, only three address translations are needed. Depending on the architecture, this can represent a significant savings by itself. Another saving is fetching and decoding the instruction itself, which has to be done only one time instead of ten. The code itself is also smaller, which can lead to more efficient memory use.</p><p>But more than that, a vector processor may have multiple <a href="/wiki/Functional_unit" class="mw-redirect" title="Functional unit">functional units</a> adding those numbers in parallel. The checking of dependencies between those numbers is not required as a vector instruction specifies multiple independent operations. This simplifies the control logic required, and can improve performance by avoiding stalls. The math operations thus completed far faster overall, the limiting factor being the time required to fetch the data from memory.</p><p>Not all problems can be attacked with this sort of solution. Including these types of instructions necessarily adds complexity to the core CPU. That complexity typically makes <i>other</i> instructions run slower—i.e., whenever it is <b>not</b> adding up many numbers in a row. The more complex instructions also add to the complexity of the decoders, which might slow down the decoding of the more common instructions such as normal adding.</p><p>In fact, vector processors work best only when there are large amounts of data to be worked on. For this reason, these sorts of CPUs were found primarily in <a href="/wiki/Supercomputer" title="Supercomputer">supercomputers</a>, as the supercomputers themselves were, in general, found in places such as weather prediction centers and physics labs, where huge amounts of data are "crunched".</p><h3><span class="mw-headline" id="Vector_instructions">Vector instructions</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Vector_processor&amp;action=edit&amp;section=6" title="Edit section: Vector instructions">edit</a><span class="mw-editsection-bracket">]</span></span></h3><div role="note" class="hatnote navigation-not-searchable">See also: <a href="/wiki/SIMD" title="SIMD">SIMD</a> and <a href="/wiki/Single_Instruction_Multiple_Threads" class="mw-redirect" title="Single Instruction Multiple Threads">Single Instruction Multiple Threads</a></div><p>The vector pseudocode example above comes with a big assumption that the vector computer can process more than ten numbers in one batch. For a greater number of numbers, it becomes unfeasible for the computer to have a register that large. As a result, the vector processor either gains the ability to perform loops itself, or exposes some sort of vector register to the programmer.</p><p>The self-repeating instructions are found in early vector computers like the STAR, where the above action would be described in a single instruction (somewhat like <code class="mw-highlight mw-highlight-lang-text" id="" style="" dir="ltr">vadd c, a, b, $10</code>). They are also found in the <a href="/wiki/X86" title="X86">x86</a> architecture as the <code class="mw-highlight mw-highlight-lang-text" id="" style="" dir="ltr">REP</code> perfix. However, only very simple calculations can be done effectively in hardware without a very large cost increase. Since all operands have to be in memory, the latency caused by access becomes huge too.</p><p>The <a href="/wiki/Cray-1" title="Cray-1">Cray-1</a> introduced the idea of using <a href="/wiki/Processor_register" title="Processor register">processor registers</a> to hold vector data in batches. This way, a lot more work can be done in each batch, at the cost of requiring the programmer to manually load/store data from/to the memory for each batch. Modern <a href="/wiki/SIMD" title="SIMD">SIMD</a> computers improve on Cray by directly using multiple ALUs, for a higher degree of parallelism compared to only using the normal scalar pipeline. Masks can be used to selectively load or store memory locations for a version of parallel logic.</p><p>GPUs, which have many small compute units, use a variant of SIMD called <a href="/wiki/Single_Instruction_Multiple_Threads" class="mw-redirect" title="Single Instruction Multiple Threads">Single Instruction Multiple Threads</a> (SIMT). This is similar to modern SIMD, with the exception that the "vector registers" are very wide and the pipelines tend to be long. The "threading" part affects the way data are swapped between the compute units. In addition, GPUs and other external vector processors like the <a href="/wiki/NEC_SX-Aurora_TSUBASA" title="NEC SX-Aurora TSUBASA">NEC SX-Aurora TSUBASA</a> may use fewer vector units than the width implies: instead of having 64 units for a 64-number-wide register, the hardware might instead do a pipelined loop over 16 units for a hybrid approach.</p><p>The difference between a traditional vector processor and a modern SIMD one can be illustrated with this variant of the "DAXPY" function:</p><div class="mw-highlight mw-highlight-lang-c mw-content-ltr" dir="ltr"><pre><span></span><span class="kt">void</span> <span class="nf">iaxpy</span><span class="p">(</span><span class="kt">size_t</span> <span class="n">n</span><span class="p">,</span> <span class="kt">int</span> <span class="n">a</span><span class="p">,</span> <span class="k">const</span> <span class="kt">int</span> <span class="n">x</span><span class="p">[],</span> <span class="kt">int</span> <span class="n">y</span><span class="p">[])</span> <span class="p">{</span>    <span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>        <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">];</span><span class="p">}</span></pre></div><p>The STAR-like code remains concise, but we now require an extra slot of memory to process the information. Two times the latency is also needed due to the extra requirement of memory access.</p><div class="mw-highlight mw-highlight-lang-gas mw-content-ltr" dir="ltr"><pre><span></span>  <span class="c">; Assume tmp is pre-allocated</span>  <span class="nf">vmul</span> <span class="no">tmp</span><span class="p">,</span> <span class="no">a</span><span class="p">,</span> <span class="no">x</span><span class="p">,</span> <span class="no">n</span> <span class="c">; tmp[i] = a * x[i]</span>  <span class="nf">vadd</span> <span class="no">y</span><span class="p">,</span> <span class="no">y</span><span class="p">,</span> <span class="no">tmp</span><span class="p">,</span> <span class="no">n</span> <span class="c">; y[i] = y[i] + tmp[i]</span>  <span class="nf">ret</span></pre></div><p>This modern SIMD machine can do most of the operation in batches. The code is mostly similar to the scalar version. We are assuming that both x and y are properly aligned here and that n is a multiple of 4, as otherwise some setup code would be needed to calculate a mask or to run a scalar version. The time taken would be basically the same as a vector implementation of <code class="mw-highlight mw-highlight-lang-text" id="" style="" dir="ltr">c = a + b</code> described above.</p><div class="mw-highlight mw-highlight-lang-gas mw-content-ltr" dir="ltr"><pre><span></span><span class="nl">vloop:</span>  <span class="nf">load32x4</span>  <span class="no">v1</span><span class="p">,</span> <span class="no">x</span>  <span class="nf">load32x4</span>  <span class="no">v2</span><span class="p">,</span> <span class="no">y</span>  <span class="nf">mul32x4</span>   <span class="no">v1</span><span class="p">,</span> <span class="no">a</span><span class="p">,</span> <span class="no">v1</span>    <span class="c">; v1&#160;:= v1 * a</span>  <span class="nf">add32x4</span>   <span class="no">v3</span><span class="p">,</span> <span class="no">v1</span><span class="p">,</span> <span class="no">v2</span>   <span class="c">; v3&#160;:= v1 + v2</span>  <span class="nf">store32x4</span> <span class="no">v3</span><span class="p">,</span> <span class="no">y</span>  <span class="nf">addl</span>      <span class="no">x</span><span class="p">,</span> <span class="no">x</span><span class="p">,</span> <span class="no">$16</span>    <span class="c">; a&#160;:= a + 16</span>  <span class="nf">addl</span>      <span class="no">y</span><span class="p">,</span> <span class="no">y</span><span class="p">,</span> <span class="no">$16</span>  <span class="nf">subl</span>      <span class="no">n</span><span class="p">,</span> <span class="no">n</span><span class="p">,</span> <span class="no">$4</span>     <span class="c">; n&#160;:= n - 4</span>  <span class="nf">jgz</span>       <span class="no">n</span><span class="p">,</span> <span class="no">vloop</span>     <span class="c">; loop back if n &gt; 0</span><span class="nl">out:</span>  <span class="nf">ret</span></pre></div><h2><span class="mw-headline" id="Performance_and_speed_up">Performance and speed up</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Vector_processor&amp;action=edit&amp;section=7" title="Edit section: Performance and speed up">edit</a><span class="mw-editsection-bracket">]</span></span></h2><p>Let <i><b>r</b></i> be the vector speed ratio and <i><b>f</b></i> be the vectorization ratio. If the time taken for the vector unit to add an array of 64 numbers is 10 times faster than its equivalent scalar counterpart, r = 10. Also, if the total number of operations in a program is 100, out of which only 10 are scalar (after vectorization), then f = 0.9, i.e., 90% of the work is done by the vector unit. It follows the achievable speed up of:</p><p><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle r/[(1-f)*r+f]}">  <semantics>    <mrow class="MJX-TeXAtom-ORD">      <mstyle displaystyle="true" scriptlevel="0">        <mi>r</mi>        <mrow class="MJX-TeXAtom-ORD">          <mo>/</mo>        </mrow>        <mo stretchy="false">[</mo>        <mo stretchy="false">(</mo>        <mn>1</mn>        <mo>&#x2212;<!-- − --></mo>        <mi>f</mi>        <mo stretchy="false">)</mo>        <mo>&#x2217;<!-- ∗ --></mo>        <mi>r</mi>        <mo>+</mo>        <mi>f</mi>        <mo stretchy="false">]</mo>      </mstyle>    </mrow>    <annotation encoding="application/x-tex">{\displaystyle r/[(1-f)*r+f]}</annotation>  </semantics></math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9d90d10baeb1dcab408e8abb5012b8743e8dc7d8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:17.958ex; height:2.843ex;" alt="r/[(1-f)*r+f]"/></span></p><p>So, even if the performance of the vector unit is very high (<span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle r=\infty }">  <semantics>    <mrow class="MJX-TeXAtom-ORD">      <mstyle displaystyle="true" scriptlevel="0">        <mi>r</mi>        <mo>=</mo>        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>      </mstyle>    </mrow>    <annotation encoding="application/x-tex">{\displaystyle r=\infty }</annotation>  </semantics></math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d38c8164ddb69351cdab28da290255fde3b846d4" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:6.471ex; height:1.676ex;" alt="r=\infty"/></span>) we get a speedup less than <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle 1/(1-f)}">  <semantics>    <mrow class="MJX-TeXAtom-ORD">      <mstyle displaystyle="true" scriptlevel="0">        <mn>1</mn>        <mrow class="MJX-TeXAtom-ORD">          <mo>/</mo>        </mrow>        <mo stretchy="false">(</mo>        <mn>1</mn>        <mo>&#x2212;<!-- − --></mo>        <mi>f</mi>        <mo stretchy="false">)</mo>      </mstyle>    </mrow>    <annotation encoding="application/x-tex">{\displaystyle 1/(1-f)}</annotation>  </semantics></math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/3b931cd65e871463804f32f213ac36f6340fd0a2" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:9.416ex; height:2.843ex;" alt="1/(1-f)"/></span>, which suggests that the ratio <i><b>f</b></i> is crucial to the performance. This ratio depends on the efficiency of the compilation like adjacency of the elements in memory.</p><h2><span class="mw-headline" id="Programming_heterogeneous_computing_architectures">Programming heterogeneous computing architectures</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Vector_processor&amp;action=edit&amp;section=8" title="Edit section: Programming heterogeneous computing architectures">edit</a><span class="mw-editsection-bracket">]</span></span></h2><p>Various machines were designed to include both traditional processors and vector processors, such as the <a href="/wiki/Fujitsu" title="Fujitsu">Fujitsu</a> AP1000 and AP3000. Programming such <a href="/wiki/Heterogeneous_computing" title="Heterogeneous computing">heterogeneous machines</a> can be difficult since developing programs that make best use of characteristics of different processors increases the programmer's burden. It increases code complexity and decreases portability of the code by requiring hardware specific code to be interleaved throughout application code.<sup id="cite_ref-2" class="reference"><a href="#cite_note-2">&#91;2&#93;</a></sup> Balancing the application workload across processors can be problematic, especially given that they typically have different performance characteristics. There are different conceptual models to deal with the problem, for example using a coordination language and program building blocks (programming libraries or higher order functions). Each block can have a different native implementation for each processor type. Users simply program using these abstractions and an intelligent compiler chooses the best implementation based on the context.<sup id="cite_ref-3" class="reference"><a href="#cite_note-3">&#91;3&#93;</a></sup></p><h2><span class="mw-headline" id="See_also">See also</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Vector_processor&amp;action=edit&amp;section=9" title="Edit section: See also">edit</a><span class="mw-editsection-bracket">]</span></span></h2><ul><li><a href="/wiki/SX_architecture" class="mw-redirect" title="SX architecture">SX architecture</a></li><li><a href="/wiki/GPGPU" class="mw-redirect" title="GPGPU">GPGPU</a></li><li><a href="/wiki/Compute_kernel" title="Compute kernel">Compute kernel</a></li><li><a href="/wiki/Stream_processing" title="Stream processing">Stream processing</a></li><li><a href="/wiki/SIMD" title="SIMD">SIMD</a></li><li><a href="/wiki/Automatic_vectorization" title="Automatic vectorization">Automatic vectorization</a></li><li><a href="/wiki/Chaining_(vector_processing)" title="Chaining (vector processing)">Chaining (vector processing)</a></li><li><a href="/wiki/Computer_for_operations_with_functions" title="Computer for operations with functions">Computer for operations with functions</a></li><li><a href="/wiki/RISC-V" title="RISC-V">RISC-V</a>, an open ISA standard with an associated variable width vector extension.</li><li><a href="/wiki/Barrel_processor" title="Barrel processor">Barrel processor</a></li><li><a href="/wiki/Tensor_processing_unit" class="mw-redirect" title="Tensor processing unit">Tensor processing unit</a></li></ul><h2><span class="mw-headline" id="References">References</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Vector_processor&amp;action=edit&amp;section=10" title="Edit section: References">edit</a><span class="mw-editsection-bracket">]</span></span></h2><div class="reflist" style="list-style-type: decimal;"><div class="mw-references-wrap"><ol class="references"><li id="cite_note-Malinovsky-1"><span class="mw-cite-backlink"><b><a href="#cite_ref-Malinovsky_1-0">^</a></b></span> <span class="reference-text"><cite id="CITEREFMalinovsky1995" class="citation book cs1">Malinovsky, B.N. (1995). <i>The history of computer technology in their faces (in Russian)</i>. Kiew: Firm "KIT". <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/5-7707-6131-8" title="Special:BookSources/5-7707-6131-8"><bdi>5-7707-6131-8</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=The+history+of+computer+technology+in+their+faces+%28in+Russian%29&amp;rft.place=Kiew&amp;rft.pub=Firm+%22KIT%22&amp;rft.date=1995&amp;rft.isbn=5-7707-6131-8&amp;rft.aulast=Malinovsky&amp;rft.aufirst=B.N.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AVector+processor" class="Z3988"></span><style data-mw-deduplicate="TemplateStyles:r982806391">.mw-parser-output cite.citation{font-style:inherit}.mw-parser-output .citation q{quotes:"\"""\"""'""'"}.mw-parser-output .id-lock-free a,.mw-parser-output .citation .cs1-lock-free a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited a,.mw-parser-output .id-lock-registration a,.mw-parser-output .citation .cs1-lock-limited a,.mw-parser-output .citation .cs1-lock-registration a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription a,.mw-parser-output .citation .cs1-lock-subscription a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration{color:#555}.mw-parser-output .cs1-subscription span,.mw-parser-output .cs1-registration span{border-bottom:1px dotted;cursor:help}.mw-parser-output .cs1-ws-icon a{background:linear-gradient(transparent,transparent),url("//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg")right 0.1em center/12px no-repeat}.mw-parser-output code.cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;font-size:100%}.mw-parser-output .cs1-visible-error{font-size:100%}.mw-parser-output .cs1-maint{display:none;color:#33aa33;margin-left:0.3em}.mw-parser-output .cs1-subscription,.mw-parser-output .cs1-registration,.mw-parser-output .cs1-format{font-size:95%}.mw-parser-output .cs1-kern-left,.mw-parser-output .cs1-kern-wl-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right,.mw-parser-output .cs1-kern-wl-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}</style></span></li><li id="cite_note-2"><span class="mw-cite-backlink"><b><a href="#cite_ref-2">^</a></b></span> <span class="reference-text"><cite id="CITEREFKunzmanKale2011" class="citation book cs1">Kunzman, D. M.; Kale, L. V. (2011). "Programming Heterogeneous Systems". <i>2011 IEEE International Symposium on Parallel and Distributed Processing Workshops and Phd Forum</i>. p.&#160;2061. <a href="/wiki/Doi_(identifier)" class="mw-redirect" title="Doi (identifier)">doi</a>:<a rel="nofollow" class="external text" href="https://doi.org/10.1109%2FIPDPS.2011.377">10.1109/IPDPS.2011.377</a>. <a href="/wiki/ISBN_(identifier)" class="mw-redirect" title="ISBN (identifier)">ISBN</a>&#160;<a href="/wiki/Special:BookSources/978-1-61284-425-1" title="Special:BookSources/978-1-61284-425-1"><bdi>978-1-61284-425-1</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=bookitem&amp;rft.atitle=Programming+Heterogeneous+Systems&amp;rft.btitle=2011+IEEE+International+Symposium+on+Parallel+and+Distributed+Processing+Workshops+and+Phd+Forum&amp;rft.pages=2061&amp;rft.date=2011&amp;rft_id=info%3Adoi%2F10.1109%2FIPDPS.2011.377&amp;rft.isbn=978-1-61284-425-1&amp;rft.aulast=Kunzman&amp;rft.aufirst=D.+M.&amp;rft.au=Kale%2C+L.+V.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AVector+processor" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r982806391"/></span></li><li id="cite_note-3"><span class="mw-cite-backlink"><b><a href="#cite_ref-3">^</a></b></span> <span class="reference-text"><cite id="CITEREFJohn_DarlintonMoustafa_GhanemYike_GuoHing_Wing_To1996" class="citation cs2">John Darlinton; Moustafa Ghanem; Yike Guo; Hing Wing To (1996), "Guided Resource Organisation in Heterogeneous Parallel Computing", <i>Journal of High Performance Computing</i>, <b>4</b> (1): 13–23, <a href="/wiki/CiteSeerX_(identifier)" class="mw-redirect" title="CiteSeerX (identifier)">CiteSeerX</a>&#160;<span class="cs1-lock-free" title="Freely accessible"><a rel="nofollow" class="external text" href="//citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.37.4309">10.1.1.37.4309</a></span></cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+High+Performance+Computing&amp;rft.atitle=Guided+Resource+Organisation+in+Heterogeneous+Parallel+Computing&amp;rft.volume=4&amp;rft.issue=1&amp;rft.pages=13-23&amp;rft.date=1996&amp;rft_id=%2F%2Fciteseerx.ist.psu.edu%2Fviewdoc%2Fsummary%3Fdoi%3D10.1.1.37.4309&amp;rft.au=John+Darlinton&amp;rft.au=Moustafa+Ghanem&amp;rft.au=Yike+Guo&amp;rft.au=Hing+Wing+To&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AVector+processor" class="Z3988"></span><link rel="mw-deduplicated-inline-style" href="mw-data:TemplateStyles:r982806391"/></span></li></ol></div></div><h2><span class="mw-headline" id="External_links">External links</span><span class="mw-editsection"><span class="mw-editsection-bracket">[</span><a href="/w/index.php?title=Vector_processor&amp;action=edit&amp;section=11" title="Edit section: External links">edit</a><span class="mw-editsection-bracket">]</span></span></h2><ul><li><a rel="nofollow" class="external text" href="http://ei.cs.vt.edu/~history/Parallel.html">The History of the Development of Parallel Computing</a> (from 1955 to 1993)</li></ul><div role="navigation" class="navbox" aria-labelledby="Parallel_computing" style="padding:3px"><table class="nowraplinks hlist mw-collapsible autocollapse navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Parallel_computing" title="Template:Parallel computing"><abbr title="View this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Parallel_computing" title="Template talk:Parallel computing"><abbr title="Discuss this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Parallel_computing&amp;action=edit"><abbr title="Edit this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">e</abbr></a></li></ul></div><div id="Parallel_computing" style="font-size:114%;margin:0 4em"><a href="/wiki/Parallel_computing" title="Parallel computing">Parallel computing</a></div></th></tr><tr><th scope="row" class="navbox-group" style="width:1%">General</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Distributed_computing" title="Distributed computing">Distributed computing</a></li><li><a href="/wiki/Parallel_computing" title="Parallel computing">Parallel computing</a></li><li><a href="/wiki/Massively_parallel" title="Massively parallel">Massively parallel</a></li><li><a href="/wiki/Cloud_computing" title="Cloud computing">Cloud computing</a></li><li><a href="/wiki/Supercomputer" title="Supercomputer">High-performance computing</a></li><li><a href="/wiki/Multiprocessing" title="Multiprocessing">Multiprocessing</a></li><li><a href="/wiki/Manycore_processor" title="Manycore processor">Manycore processor</a></li><li><a href="/wiki/General-purpose_computing_on_graphics_processing_units" title="General-purpose computing on graphics processing units">GPGPU</a></li><li><a href="/wiki/Computer_network" title="Computer network">Computer network</a></li><li><a href="/wiki/Systolic_array" title="Systolic array">Systolic array</a></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Levels</th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Bit-level_parallelism" title="Bit-level parallelism">Bit</a></li><li><a href="/wiki/Instruction-level_parallelism" title="Instruction-level parallelism">Instruction</a></li><li><a href="/wiki/Task_parallelism" title="Task parallelism">Thread</a></li><li><a href="/wiki/Task_parallelism" title="Task parallelism">Task</a></li><li><a href="/wiki/Data_parallelism" title="Data parallelism">Data</a></li><li><a href="/wiki/Memory-level_parallelism" title="Memory-level parallelism">Memory</a></li><li><a href="/wiki/Loop-level_parallelism" title="Loop-level parallelism">Loop</a></li><li><a href="/wiki/Pipeline_(computing)" title="Pipeline (computing)">Pipeline</a></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Multithreading_(computer_architecture)" title="Multithreading (computer architecture)">Multithreading</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Temporal_multithreading" title="Temporal multithreading">Temporal</a></li><li><a href="/wiki/Simultaneous_multithreading" title="Simultaneous multithreading">Simultaneous</a> (SMT)</li><li><a href="/wiki/Speculative_multithreading" title="Speculative multithreading">Speculative</a> (SpMT)</li><li><a href="/wiki/Preemption_(computing)" title="Preemption (computing)">Preemptive</a></li><li><a href="/wiki/Computer_multitasking#Cooperative_multitasking" title="Computer multitasking">Cooperative</a></li><li><a href="/wiki/Bulldozer_(microarchitecture)#Bulldozer_core" title="Bulldozer (microarchitecture)">Clustered Multi-Thread</a> (CMT)</li><li><a href="/wiki/Hardware_scout" title="Hardware scout">Hardware scout</a></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Theory</th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Parallel_random-access_machine" class="mw-redirect" title="Parallel random-access machine">PRAM model</a></li><li><a href="/wiki/Parallel_external_memory" title="Parallel external memory">PEM Model</a></li><li><a href="/wiki/Analysis_of_parallel_algorithms" title="Analysis of parallel algorithms">Analysis of parallel algorithms</a></li><li><a href="/wiki/Amdahl%27s_law" title="Amdahl&#39;s law">Amdahl's law</a></li><li><a href="/wiki/Gustafson%27s_law" title="Gustafson&#39;s law">Gustafson's law</a></li><li><a href="/wiki/Cost_efficiency" title="Cost efficiency">Cost efficiency</a></li><li><a href="/wiki/Karp%E2%80%93Flatt_metric" title="Karp–Flatt metric">Karp–Flatt metric</a></li><li><a href="/wiki/Parallel_slowdown" title="Parallel slowdown">Slowdown</a></li><li><a href="/wiki/Speedup" title="Speedup">Speedup</a></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Elements</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Process_(computing)" title="Process (computing)">Process</a></li><li><a href="/wiki/Thread_(computing)" title="Thread (computing)">Thread</a></li><li><a href="/wiki/Fiber_(computer_science)" title="Fiber (computer science)">Fiber</a></li><li><a href="/wiki/Instruction_window" title="Instruction window">Instruction window</a></li><li><a href="/wiki/Array_data_structure" title="Array data structure">Array data structure</a></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Coordination</th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Multiprocessing" title="Multiprocessing">Multiprocessing</a></li><li><a href="/wiki/Memory_coherence" title="Memory coherence">Memory coherency</a></li><li><a href="/wiki/Cache_coherence" title="Cache coherence">Cache coherency</a></li><li><a href="/wiki/Cache_invalidation" title="Cache invalidation">Cache invalidation</a></li><li><a href="/wiki/Barrier_(computer_science)" title="Barrier (computer science)">Barrier</a></li><li><a href="/wiki/Synchronization_(computer_science)" title="Synchronization (computer science)">Synchronization</a></li><li><a href="/wiki/Application_checkpointing" title="Application checkpointing">Application checkpointing</a></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Computer_programming" title="Computer programming">Programming</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Stream_processing" title="Stream processing">Stream processing</a></li><li><a href="/wiki/Dataflow_programming" title="Dataflow programming">Dataflow programming</a></li><li><a href="/wiki/Parallel_programming_model" title="Parallel programming model">Models</a><ul><li><a href="/wiki/Implicit_parallelism" title="Implicit parallelism">Implicit parallelism</a></li><li><a href="/wiki/Explicit_parallelism" title="Explicit parallelism">Explicit parallelism</a></li><li><a href="/wiki/Concurrency_(computer_science)" title="Concurrency (computer science)">Concurrency</a></li></ul></li><li><a href="/wiki/Non-blocking_algorithm" title="Non-blocking algorithm">Non-blocking algorithm</a></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Computer_hardware" title="Computer hardware">Hardware</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Flynn%27s_taxonomy" title="Flynn&#39;s taxonomy">Flynn's taxonomy</a><ul><li><a href="/wiki/SISD" title="SISD">SISD</a></li><li><a href="/wiki/SIMD" title="SIMD">SIMD</a></li><li><a href="/wiki/Single_instruction,_multiple_threads" title="Single instruction, multiple threads">SIMT</a></li><li><a href="/wiki/MISD" title="MISD">MISD</a></li><li><a href="/wiki/MIMD" title="MIMD">MIMD</a></li></ul></li><li><a href="/wiki/Dataflow_architecture" title="Dataflow architecture">Dataflow architecture</a></li><li><a href="/wiki/Instruction_pipelining" title="Instruction pipelining">Pipelined processor</a></li><li><a href="/wiki/Superscalar_processor" title="Superscalar processor">Superscalar processor</a></li><li><a class="mw-selflink selflink">Vector processor</a></li><li><a href="/wiki/Multiprocessing" title="Multiprocessing">Multiprocessor</a><ul><li><a href="/wiki/Symmetric_multiprocessing" title="Symmetric multiprocessing">symmetric</a></li><li><a href="/wiki/Asymmetric_multiprocessing" title="Asymmetric multiprocessing">asymmetric</a></li></ul></li><li><a href="/wiki/Semiconductor_memory" title="Semiconductor memory">Memory</a><ul><li><a href="/wiki/Shared_memory" title="Shared memory">shared</a></li><li><a href="/wiki/Distributed_memory" title="Distributed memory">distributed</a></li><li><a href="/wiki/Distributed_shared_memory" title="Distributed shared memory">distributed shared</a></li><li><a href="/wiki/Uniform_memory_access" title="Uniform memory access">UMA</a></li><li><a href="/wiki/Non-uniform_memory_access" title="Non-uniform memory access">NUMA</a></li><li><a href="/wiki/Cache-only_memory_architecture" title="Cache-only memory architecture">COMA</a></li></ul></li><li><a href="/wiki/Massively_parallel" title="Massively parallel">Massively parallel computer</a></li><li><a href="/wiki/Computer_cluster" title="Computer cluster">Computer cluster</a></li><li><a href="/wiki/Grid_computing" title="Grid computing">Grid computer</a></li><li><a href="/wiki/Hardware_acceleration" title="Hardware acceleration">Hardware acceleration</a></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Application_programming_interface" class="mw-redirect" title="Application programming interface">APIs</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Ateji_PX" title="Ateji PX">Ateji PX</a></li><li><a href="/wiki/Boost_(C%2B%2B_libraries)" title="Boost (C++ libraries)">Boost</a></li><li><a href="/wiki/Chapel_(programming_language)" title="Chapel (programming language)">Chapel</a></li><li><a href="/wiki/HPX" title="HPX">HPX</a></li><li><a href="/wiki/Charm%2B%2B" title="Charm++">Charm++</a></li><li><a href="/wiki/Cilk" title="Cilk">Cilk</a></li><li><a href="/wiki/Coarray_Fortran" title="Coarray Fortran">Coarray Fortran</a></li><li><a href="/wiki/CUDA" title="CUDA">CUDA</a></li><li><a href="/wiki/Dryad_(programming)" title="Dryad (programming)">Dryad</a></li><li><a href="/wiki/C%2B%2B_AMP" title="C++ AMP">C++ AMP</a></li><li><a href="/wiki/Global_Arrays" title="Global Arrays">Global Arrays</a></li><li><a href="/wiki/GPUOpen" title="GPUOpen">GPUOpen</a></li><li><a href="/wiki/Message_Passing_Interface" title="Message Passing Interface">MPI</a></li><li><a href="/wiki/OpenMP" title="OpenMP">OpenMP</a></li><li><a href="/wiki/OpenCL" title="OpenCL">OpenCL</a></li><li><a href="/wiki/OpenHMPP" title="OpenHMPP">OpenHMPP</a></li><li><a href="/wiki/OpenACC" title="OpenACC">OpenACC</a></li><li><a href="/wiki/Parallel_Extensions" title="Parallel Extensions">Parallel Extensions</a></li><li><a href="/wiki/Parallel_Virtual_Machine" title="Parallel Virtual Machine">PVM</a></li><li><a href="/wiki/POSIX_Threads" title="POSIX Threads">POSIX Threads</a></li><li><a href="/wiki/RaftLib" title="RaftLib">RaftLib</a></li><li><a href="/wiki/Unified_Parallel_C" title="Unified Parallel C">UPC</a></li><li><a href="/wiki/Threading_Building_Blocks" title="Threading Building Blocks">TBB</a></li><li><a href="/wiki/ZPL_(programming_language)" title="ZPL (programming language)">ZPL</a></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Problems</th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Automatic_parallelization" title="Automatic parallelization">Automatic parallelization</a></li><li><a href="/wiki/Deadlock" title="Deadlock">Deadlock</a></li><li><a href="/wiki/Deterministic_algorithm" title="Deterministic algorithm">Deterministic algorithm</a></li><li><a href="/wiki/Embarrassingly_parallel" title="Embarrassingly parallel">Embarrassingly parallel</a></li><li><a href="/wiki/Parallel_slowdown" title="Parallel slowdown">Parallel slowdown</a></li><li><a href="/wiki/Race_condition" title="Race condition">Race condition</a></li><li><a href="/wiki/Software_lockout" title="Software lockout">Software lockout</a></li><li><a href="/wiki/Scalability" title="Scalability">Scalability</a></li><li><a href="/wiki/Starvation_(computer_science)" title="Starvation (computer science)">Starvation</a></li></ul></div></td></tr><tr><td class="navbox-abovebelow" colspan="2"><div><ul><li><img alt="Category" src="//upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/16px-Folder_Hexagonal_Icon.svg.png" decoding="async" title="Category" width="16" height="14" srcset="//upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/24px-Folder_Hexagonal_Icon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/4/48/Folder_Hexagonal_Icon.svg/32px-Folder_Hexagonal_Icon.svg.png 2x" data-file-width="36" data-file-height="31" />&#160;<a href="/wiki/Category:Parallel_computing" title="Category:Parallel computing">Category: Parallel computing</a></li></ul></div></td></tr></tbody></table></div><div role="navigation" class="navbox" aria-labelledby="Processor_technologies" style="padding:3px"><table class="nowraplinks mw-collapsible autocollapse navbox-inner" style="border-spacing:0;background:transparent;color:inherit"><tbody><tr><th scope="col" class="navbox-title" colspan="2"><div class="plainlinks hlist navbar mini"><ul><li class="nv-view"><a href="/wiki/Template:Processor_technologies" title="Template:Processor technologies"><abbr title="View this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">v</abbr></a></li><li class="nv-talk"><a href="/wiki/Template_talk:Processor_technologies" title="Template talk:Processor technologies"><abbr title="Discuss this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">t</abbr></a></li><li class="nv-edit"><a class="external text" href="https://en.wikipedia.org/w/index.php?title=Template:Processor_technologies&amp;action=edit"><abbr title="Edit this template" style=";;background:none transparent;border:none;-moz-box-shadow:none;-webkit-box-shadow:none;box-shadow:none; padding:0;">e</abbr></a></li></ul></div><div id="Processor_technologies" style="font-size:114%;margin:0 4em"><a href="/wiki/Processor_(computing)" title="Processor (computing)">Processor technologies</a></div></th></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Model_of_computation" title="Model of computation">Models</a></th><td class="navbox-list navbox-odd hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Turing_machine" title="Turing machine">Turing machine</a><ul><li><a href="/wiki/Universal_Turing_machine" title="Universal Turing machine">Universal</a></li><li><a href="/wiki/Post%E2%80%93Turing_machine" title="Post–Turing machine">Post–Turing</a></li><li><a href="/wiki/Quantum_Turing_machine" title="Quantum Turing machine">Quantum</a></li></ul></li><li><a href="/wiki/Belt_machine" class="mw-redirect" title="Belt machine">Belt machine</a></li><li><a href="/wiki/Stack_machine" title="Stack machine">Stack machine</a></li><li><a href="/wiki/Finite-state_machine" title="Finite-state machine">Finite-state machine</a><ul><li><a href="/wiki/Finite_state_machine_with_datapath" class="mw-redirect" title="Finite state machine with datapath">with datapath</a></li><li><a href="/wiki/Hierarchical_state_machine" class="mw-redirect" title="Hierarchical state machine">Hierarchical</a></li><li><a href="/wiki/Queue_automaton" title="Queue automaton">Queue automaton</a></li></ul></li><li><a href="/wiki/Register_machine" title="Register machine">Register machines</a><ul><li><a href="/wiki/Counter_machine" title="Counter machine">Counter</a></li><li><a href="/wiki/Pointer_machine" title="Pointer machine">Pointer</a></li><li><a href="/wiki/Random-access_machine" title="Random-access machine">Random-access</a></li><li><a href="/wiki/Random-access_stored-program_machine" title="Random-access stored-program machine">Random-access stored program</a></li></ul></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Computer_architecture" title="Computer architecture">Architecture</a></th><td class="navbox-list navbox-even hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Microarchitecture" title="Microarchitecture">Microarchitecture</a></li><li><a href="/wiki/Von_Neumann_architecture" title="Von Neumann architecture">Von Neumann</a></li><li><a href="/wiki/Harvard_architecture" title="Harvard architecture">Harvard</a><ul><li><a href="/wiki/Modified_Harvard_architecture" title="Modified Harvard architecture">modified</a></li></ul></li><li><a href="/wiki/Dataflow_architecture" title="Dataflow architecture">Dataflow</a></li><li><a href="/wiki/Transport_triggered_architecture" title="Transport triggered architecture">Transport-triggered</a></li><li><a href="/wiki/Cellular_architecture" title="Cellular architecture">Cellular</a></li><li><a href="/wiki/Endianness" title="Endianness">Endianness</a></li><li><a href="/wiki/Computer_data_storage" title="Computer data storage">Memory access</a><ul><li><a href="/wiki/Non-uniform_memory_access" title="Non-uniform memory access">NUMA</a></li><li><a href="/wiki/Heterogenous_Unified_Memory_Access" class="mw-redirect" title="Heterogenous Unified Memory Access">HUMA</a></li><li><a href="/wiki/Load/store_architecture" class="mw-redirect" title="Load/store architecture">Load/store</a></li><li><a href="/wiki/Register_memory_architecture" title="Register memory architecture">Register/memory</a></li></ul></li><li><a href="/wiki/Cache_hierarchy" title="Cache hierarchy">Cache hierarchy</a></li><li><a href="/wiki/Memory_hierarchy" title="Memory hierarchy">Memory hierarchy</a><ul><li><a href="/wiki/Virtual_memory" title="Virtual memory">Virtual memory</a></li><li><a href="/wiki/Secondary_storage" class="mw-redirect" title="Secondary storage">Secondary storage</a></li></ul></li><li><a href="/wiki/Heterogeneous_System_Architecture" title="Heterogeneous System Architecture">Heterogeneous</a></li><li><a href="/wiki/Fabric_computing" title="Fabric computing">Fabric</a></li><li><a href="/wiki/Multiprocessing" title="Multiprocessing">Multiprocessing</a></li><li><a href="/wiki/Cognitive_computing" title="Cognitive computing">Cognitive</a></li><li><a href="/wiki/Neuromorphic_engineering" title="Neuromorphic engineering">Neuromorphic</a></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Instruction_set_architecture" title="Instruction set architecture">Instruction set<br />architectures</a></th><td class="navbox-list navbox-odd hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:1%">Types</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Complex_instruction_set_computer" title="Complex instruction set computer">CISC</a></li><li><a href="/wiki/Reduced_instruction_set_computer" title="Reduced instruction set computer">RISC</a></li><li><a href="/wiki/Application-specific_instruction_set_processor" title="Application-specific instruction set processor">Application-specific</a></li><li><a href="/wiki/Explicit_data_graph_execution" title="Explicit data graph execution">EDGE</a><ul><li><a href="/wiki/TRIPS_architecture" title="TRIPS architecture">TRIPS</a></li></ul></li><li><a href="/wiki/Very_long_instruction_word" title="Very long instruction word">VLIW</a><ul><li><a href="/wiki/Explicitly_parallel_instruction_computing" title="Explicitly parallel instruction computing">EPIC</a></li></ul></li><li><a href="/wiki/Minimal_instruction_set_computer" title="Minimal instruction set computer">MISC</a></li><li><a href="/wiki/One_instruction_set_computer" class="mw-redirect" title="One instruction set computer">OISC</a></li><li><a href="/wiki/No_instruction_set_computing" title="No instruction set computing">NISC</a></li><li><a href="/wiki/Zero_instruction_set_computer" class="mw-redirect" title="Zero instruction set computer">ZISC</a></li><li><a href="/wiki/Comparison_of_instruction_set_architectures" title="Comparison of instruction set architectures">Comparison</a><ul><li><a href="/wiki/Addressing_mode" title="Addressing mode">Addressing modes</a></li></ul></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Instruction sets</th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/X86" title="X86">x86</a></li><li><a href="/wiki/ARM_architecture" title="ARM architecture">ARM</a></li><li><a href="/wiki/MIPS_architecture" title="MIPS architecture">MIPS</a></li><li><a href="/wiki/Power_ISA" title="Power ISA">Power ISA</a></li><li><a href="/wiki/SPARC" title="SPARC">SPARC</a></li><li><a href="/wiki/IA-64" title="IA-64">Itanium</a></li><li><a href="/wiki/Unicore" title="Unicore">Unicore</a></li><li><a href="/wiki/MicroBlaze" title="MicroBlaze">MicroBlaze</a></li><li><a href="/wiki/RISC-V" title="RISC-V">RISC-V</a></li><li><a href="/wiki/Little_man_computer" title="Little man computer">LMC</a></li><li><a href="/wiki/List_of_instruction_sets" class="mw-redirect" title="List of instruction sets">Others</a></li></ul></div></td></tr></tbody></table><div></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Instruction_cycle" title="Instruction cycle">Execution</a></th><td class="navbox-list navbox-odd hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Instruction_pipelining" title="Instruction pipelining">Instruction pipelining</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Pipeline_stall" title="Pipeline stall">Pipeline stall</a></li><li><a href="/wiki/Operand_forwarding" title="Operand forwarding">Operand forwarding</a></li><li><a href="/wiki/Classic_RISC_pipeline" title="Classic RISC pipeline">Classic RISC pipeline</a></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Hazard_(computer_architecture)" title="Hazard (computer architecture)">Hazards</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Data_dependency" title="Data dependency">Data dependency</a></li><li><a href="/wiki/Structural_hazard" class="mw-redirect" title="Structural hazard">Structural</a></li><li><a href="/wiki/Control_hazard" class="mw-redirect" title="Control hazard">Control</a></li><li><a href="/wiki/False_sharing" title="False sharing">False sharing</a></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Out-of-order_execution" title="Out-of-order execution">Out-of-order</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Tomasulo_algorithm" title="Tomasulo algorithm">Tomasulo algorithm</a><ul><li><a href="/wiki/Reservation_station" title="Reservation station">Reservation station</a></li><li><a href="/wiki/Re-order_buffer" title="Re-order buffer">Re-order buffer</a></li></ul></li><li><a href="/wiki/Register_renaming" title="Register renaming">Register renaming</a></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Speculative_execution" title="Speculative execution">Speculative</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Branch_predictor" title="Branch predictor">Branch prediction</a></li><li><a href="/wiki/Memory_dependence_prediction" title="Memory dependence prediction">Memory dependence prediction</a></li></ul></div></td></tr></tbody></table><div></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Parallel_computing" title="Parallel computing">Parallelism</a></th><td class="navbox-list navbox-odd hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:1%">Level</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Bit-level_parallelism" title="Bit-level parallelism">Bit</a><ul><li><a href="/wiki/Bit-serial_architecture" title="Bit-serial architecture">Bit-serial</a></li><li><a href="/wiki/Word_(computer_architecture)" title="Word (computer architecture)">Word</a></li></ul></li><li><a href="/wiki/Instruction-level_parallelism" title="Instruction-level parallelism">Instruction</a></li><li><a href="/wiki/Instruction_pipelining" title="Instruction pipelining">Pipelining</a><ul><li><a href="/wiki/Scalar_processor" title="Scalar processor">Scalar</a></li><li><a href="/wiki/Superscalar_processor" title="Superscalar processor">Superscalar</a></li></ul></li><li><a href="/wiki/Task_parallelism" title="Task parallelism">Task</a><ul><li><a href="/wiki/Thread_(computing)" title="Thread (computing)">Thread</a></li><li><a href="/wiki/Process_(computing)" title="Process (computing)">Process</a></li></ul></li><li><a href="/wiki/Data_parallelism" title="Data parallelism">Data</a><ul><li><a class="mw-selflink selflink">Vector</a></li></ul></li><li><a href="/wiki/Memory-level_parallelism" title="Memory-level parallelism">Memory</a></li><li><a href="/wiki/Distributed_architecture" class="mw-redirect" title="Distributed architecture">Distributed</a></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Multithreading_(computer_architecture)" title="Multithreading (computer architecture)">Multithreading</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Temporal_multithreading" title="Temporal multithreading">Temporal</a></li><li><a href="/wiki/Simultaneous_multithreading" title="Simultaneous multithreading">Simultaneous</a><ul><li><a href="/wiki/Hyper-threading" title="Hyper-threading">Hyperthreading</a></li></ul></li><li><a href="/wiki/Speculative_multithreading" title="Speculative multithreading">Speculative</a></li><li><a href="/wiki/Preemption_(computing)" title="Preemption (computing)">Preemptive</a></li><li><a href="/wiki/Cooperative_multithreading" class="mw-redirect" title="Cooperative multithreading">Cooperative</a></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Flynn%27s_taxonomy" title="Flynn&#39;s taxonomy">Flynn's taxonomy</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/SISD" title="SISD">SISD</a></li><li><a href="/wiki/SIMD" title="SIMD">SIMD</a><ul><li><a href="/wiki/SWAR" title="SWAR">SWAR</a></li></ul></li><li><a href="/wiki/Single_instruction,_multiple_threads" title="Single instruction, multiple threads">SIMT</a></li><li><a href="/wiki/MISD" title="MISD">MISD</a></li><li><a href="/wiki/MIMD" title="MIMD">MIMD</a><ul><li><a href="/wiki/SPMD" title="SPMD">SPMD</a></li></ul></li></ul></div></td></tr></tbody></table><div></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Computer_performance" title="Computer performance">Processor<br />performance</a></th><td class="navbox-list navbox-even hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Transistor_count" title="Transistor count">Transistor count</a></li><li><a href="/wiki/Instructions_per_cycle" title="Instructions per cycle">Instructions per cycle</a> (IPC)<ul><li><a href="/wiki/Cycles_per_instruction" title="Cycles per instruction">Cycles per instruction</a> (CPI)</li></ul></li><li><a href="/wiki/Instructions_per_second" title="Instructions per second">Instructions per second</a> (IPS)</li><li><a href="/wiki/FLOPS" title="FLOPS">Floating-point operations per second</a> (FLOPS)</li><li><a href="/wiki/Transactions_per_second" title="Transactions per second">Transactions per second</a> (TPS)</li><li><a href="/wiki/SUPS" title="SUPS">Synaptic updates per second</a> (SUPS)</li><li><a href="/wiki/Performance_per_watt" title="Performance per watt">Performance per watt</a> (PPW)</li><li><a href="/wiki/Cache_performance_measurement_and_metric" title="Cache performance measurement and metric">Cache performance metrics</a></li><li><a href="/wiki/Computer_performance_by_orders_of_magnitude" title="Computer performance by orders of magnitude">Computer performance by orders of magnitude</a></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Processor_(computing)" title="Processor (computing)">Types</a></th><td class="navbox-list navbox-odd hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Central_processing_unit" title="Central processing unit">Central processing unit</a> (CPU)</li><li><a href="/wiki/Graphics_processing_unit" title="Graphics processing unit">Graphics processing unit</a> (GPU)<ul><li><a href="/wiki/General-purpose_computing_on_graphics_processing_units" title="General-purpose computing on graphics processing units">GPGPU</a></li></ul></li><li><a class="mw-selflink selflink">Vector</a></li><li><a href="/wiki/Barrel_processor" title="Barrel processor">Barrel</a></li><li><a href="/wiki/Stream_processing" title="Stream processing">Stream</a></li><li><a href="/wiki/Coprocessor" title="Coprocessor">Coprocessor</a></li><li><a href="/wiki/Application-specific_integrated_circuit" title="Application-specific integrated circuit">ASIC</a></li><li><a href="/wiki/Field-programmable_gate_array" title="Field-programmable gate array">FPGA</a></li><li><a href="/wiki/Complex_programmable_logic_device" title="Complex programmable logic device">CPLD</a></li><li><a href="/wiki/Multi-chip_module" title="Multi-chip module">Multi-chip module</a> (MCM)</li><li><a href="/wiki/System_in_package" class="mw-redirect" title="System in package">System in package</a> (SiP)</li></ul></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:1%">By application</th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Microprocessor" title="Microprocessor">Microprocessor</a></li><li><a href="/wiki/Microcontroller" title="Microcontroller">Microcontroller</a></li><li><a href="/wiki/Mobile_processor" title="Mobile processor">Mobile</a></li><li><a href="/wiki/Notebook_processor" title="Notebook processor">Notebook</a></li><li><a href="/wiki/Ultra-low-voltage_processor" title="Ultra-low-voltage processor">Ultra-low-voltage</a></li><li><a href="/wiki/Application-specific_instruction_set_processor" title="Application-specific instruction set processor">ASIP</a></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Systems<br />on chip</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/System_on_a_chip" title="System on a chip">System on a chip</a> (SoC)</li><li><a href="/wiki/Multiprocessor_system-on-chip" class="mw-redirect" title="Multiprocessor system-on-chip">Multiprocessor</a> (MPSoC)</li><li><a href="/wiki/Programmable_system-on-chip" class="mw-redirect" title="Programmable system-on-chip">Programmable</a> (PSoC)</li><li><a href="/wiki/Network_on_a_chip" title="Network on a chip">Network on a chip</a> (NoC)</li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Hardware_acceleration" title="Hardware acceleration">Hardware<br />accelerators</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/AI_accelerator" title="AI accelerator">AI accelerator</a></li><li><a href="/wiki/Vision_processing_unit" title="Vision processing unit">Vision processing unit</a> (VPU)</li><li><a href="/wiki/Physics_processing_unit" title="Physics processing unit">Physics processing unit</a> (PPU)</li><li><a href="/wiki/Digital_signal_processor" title="Digital signal processor">Digital signal processor</a> (DSP)</li><li><a href="/wiki/Tensor_processing_unit" class="mw-redirect" title="Tensor processing unit">Tensor processing unit</a> (TPU)</li><li><a href="/wiki/Secure_cryptoprocessor" title="Secure cryptoprocessor">Secure cryptoprocessor</a></li><li><a href="/wiki/Network_processor" title="Network processor">Network processor</a></li><li><a href="/wiki/Baseband_processor" title="Baseband processor">Baseband processor</a></li></ul></div></td></tr></tbody></table><div></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Word_(computer_architecture)" title="Word (computer architecture)">Word size</a></th><td class="navbox-list navbox-odd hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/1-bit_computing" title="1-bit computing">1-bit</a></li><li><a href="/wiki/4-bit_computing" title="4-bit computing">4-bit</a></li><li><a href="/wiki/8-bit_computing" title="8-bit computing">8-bit</a></li><li><a href="/wiki/12-bit_computing" title="12-bit computing">12-bit</a></li><li><a href="/wiki/Apollo_Guidance_Computer" title="Apollo Guidance Computer">15-bit</a></li><li><a href="/wiki/16-bit_computing" title="16-bit computing">16-bit</a></li><li><a href="/wiki/24-bit_computing" title="24-bit computing">24-bit</a></li><li><a href="/wiki/32-bit_computing" title="32-bit computing">32-bit</a></li><li><a href="/wiki/48-bit_computing" title="48-bit computing">48-bit</a></li><li><a href="/wiki/64-bit_computing" title="64-bit computing">64-bit</a></li><li><a href="/wiki/128-bit_computing" title="128-bit computing">128-bit</a></li><li><a href="/wiki/256-bit_computing" title="256-bit computing">256-bit</a></li><li><a href="/wiki/512-bit_computing" title="512-bit computing">512-bit</a></li><li><a href="/wiki/Bit_slicing" title="Bit slicing">bit slicing</a></li><li><a href="/wiki/Word_(computer_architecture)#Table_of_word_sizes" title="Word (computer architecture)">others</a><ul><li><a href="/wiki/Word_(computer_architecture)#Variable_word_architectures" title="Word (computer architecture)">variable</a></li></ul></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Core count</th><td class="navbox-list navbox-even hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Single-core" title="Single-core">Single-core</a></li><li><a href="/wiki/Multi-core_processor" title="Multi-core processor">Multi-core</a></li><li><a href="/wiki/Manycore_processor" title="Manycore processor">Manycore</a></li><li><a href="/wiki/Heterogeneous_computing" title="Heterogeneous computing">Heterogeneous architecture</a></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Components</th><td class="navbox-list navbox-odd hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Processor_core" class="mw-redirect" title="Processor core">Core</a></li><li><a href="/wiki/Cache_(computing)" title="Cache (computing)">Cache</a><ul><li><a href="/wiki/CPU_cache" title="CPU cache">CPU cache</a></li><li><a href="/wiki/Cache_replacement_policies" title="Cache replacement policies">replacement policies</a></li><li><a href="/wiki/Cache_coherence" title="Cache coherence">coherence</a></li></ul></li><li><a href="/wiki/Bus_(computing)" title="Bus (computing)">Bus</a></li><li><a href="/wiki/Clock_rate" title="Clock rate">Clock rate</a></li><li><a href="/wiki/Clock_signal" title="Clock signal">Clock signal</a></li><li><a href="/wiki/FIFO_(computing_and_electronics)" title="FIFO (computing and electronics)">FIFO</a></li></ul></div><table class="nowraplinks navbox-subgroup" style="border-spacing:0"><tbody><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Execution_unit" title="Execution unit">Functional units</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Arithmetic_logic_unit" title="Arithmetic logic unit">Arithmetic logic unit</a> (ALU)</li><li><a href="/wiki/Address_generation_unit" title="Address generation unit">Address generation unit</a> (AGU)</li><li><a href="/wiki/Floating-point_unit" title="Floating-point unit">Floating-point unit</a> (FPU)</li><li><a href="/wiki/Memory_management_unit" title="Memory management unit">Memory management unit</a> (MMU)<ul><li><a href="/wiki/Load%E2%80%93store_unit" title="Load–store unit">Load–store unit</a></li><li><a href="/wiki/Translation_lookaside_buffer" title="Translation lookaside buffer">Translation lookaside buffer</a> (TLB)</li></ul></li><li><a href="/wiki/Memory_controller" title="Memory controller">Integrated memory controller</a> (IMC)</li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Digital_logic" class="mw-redirect" title="Digital logic">Logic</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Combinational_logic" title="Combinational logic">Combinational</a></li><li><a href="/wiki/Sequential_logic" title="Sequential logic">Sequential</a></li><li><a href="/wiki/Glue_logic" title="Glue logic">Glue</a></li><li><a href="/wiki/Logic_gate" title="Logic gate">Logic gate</a><ul><li><a href="/wiki/Quantum_logic_gate" title="Quantum logic gate">Quantum</a></li><li><a href="/wiki/Gate_array" title="Gate array">Array</a></li></ul></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Hardware_register" title="Hardware register">Registers</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Processor_register" title="Processor register">Processor register</a></li><li><a href="/wiki/Status_register" title="Status register">Status register</a></li><li><a href="/wiki/Stack_register" title="Stack register">Stack register</a></li><li><a href="/wiki/Register_file" title="Register file">Register file</a></li><li><a href="/wiki/Memory_buffer_register" title="Memory buffer register">Memory buffer</a></li><li><a href="/wiki/Program_counter" title="Program counter">Program counter</a></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Control unit</th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Instruction_unit" title="Instruction unit">Instruction unit</a></li><li><a href="/wiki/Data_buffer" title="Data buffer">Data buffer</a></li><li><a href="/wiki/Write_buffer" title="Write buffer">Write buffer</a></li><li><a href="/wiki/Microcode" title="Microcode">Microcode</a> <a href="/wiki/ROM_image" title="ROM image">ROM</a></li><li><a href="/wiki/Counter_(digital)" title="Counter (digital)">Counter</a></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Datapath" title="Datapath">Datapath</a></th><td class="navbox-list navbox-even" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Multiplexer" title="Multiplexer">Multiplexer</a></li><li><a href="/wiki/Demultiplexer" class="mw-redirect" title="Demultiplexer">Demultiplexer</a></li><li><a href="/wiki/Adder_(electronics)" title="Adder (electronics)">Adder</a></li><li><a href="/wiki/Binary_multiplier" title="Binary multiplier">Multiplier</a><ul><li><a href="/wiki/CPU_multiplier" title="CPU multiplier">CPU</a></li></ul></li><li><a href="/wiki/Binary_decoder" title="Binary decoder">Binary decoder</a><ul><li><a href="/wiki/Address_decoder" title="Address decoder">Address decoder</a></li><li><a href="/wiki/Sum_addressed_decoder" class="mw-redirect" title="Sum addressed decoder">Sum addressed decoder</a></li></ul></li><li><a href="/wiki/Barrel_shifter" title="Barrel shifter">Barrel shifter</a></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Electronic_circuit" title="Electronic circuit">Circuitry</a></th><td class="navbox-list navbox-odd" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Integrated_circuit" title="Integrated circuit">Integrated circuit</a><ul><li><a href="/wiki/Three-dimensional_integrated_circuit" title="Three-dimensional integrated circuit">3D</a></li><li><a href="/wiki/Mixed-signal_integrated_circuit" title="Mixed-signal integrated circuit">Mixed-signal</a></li><li><a href="/wiki/Power_management_integrated_circuit" title="Power management integrated circuit">Power management</a></li></ul></li><li><a href="/wiki/Boolean_circuit" title="Boolean circuit">Boolean</a></li><li><a href="/wiki/Digital_circuit" class="mw-redirect" title="Digital circuit">Digital</a></li><li><a href="/wiki/Analog_circuit" class="mw-redirect" title="Analog circuit">Analog</a></li><li><a href="/wiki/Quantum_circuit" title="Quantum circuit">Quantum</a></li><li><a href="/wiki/Switch#Electronic_switches" title="Switch">Switch</a></li></ul></div></td></tr></tbody></table><div></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%"><a href="/wiki/Power_management" title="Power management">Power<br />management</a></th><td class="navbox-list navbox-even hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/Power_Management_Unit" title="Power Management Unit">PMU</a></li><li><a href="/wiki/Advanced_Power_Management" title="Advanced Power Management">APM</a></li><li><a href="/wiki/Advanced_Configuration_and_Power_Interface" title="Advanced Configuration and Power Interface">ACPI</a></li><li><a href="/wiki/Dynamic_frequency_scaling" title="Dynamic frequency scaling">Dynamic frequency scaling</a></li><li><a href="/wiki/Dynamic_voltage_scaling" title="Dynamic voltage scaling">Dynamic voltage scaling</a></li><li><a href="/wiki/Clock_gating" title="Clock gating">Clock gating</a></li><li><a href="/wiki/Performance_per_watt" title="Performance per watt">Performance per watt</a> (PPW)</li><li><a href="/w/index.php?title=Race_to_sleep&amp;action=edit&amp;redlink=1" class="new" title="Race to sleep (page does not exist)">Race to sleep</a></li></ul></div></td></tr><tr><th scope="row" class="navbox-group" style="width:1%">Related</th><td class="navbox-list navbox-odd hlist" style="text-align:left;border-left-width:2px;border-left-style:solid;width:100%;padding:0px"><div style="padding:0em 0.25em"><ul><li><a href="/wiki/History_of_general-purpose_CPUs" title="History of general-purpose CPUs">History of general-purpose CPUs</a></li><li><a href="/wiki/Microprocessor_chronology" title="Microprocessor chronology">Microprocessor chronology</a></li><li><a href="/wiki/Processor_design" title="Processor design">Processor design</a></li><li><a href="/wiki/Digital_electronics" title="Digital electronics">Digital electronics</a></li><li><a href="/wiki/Hardware_security_module" title="Hardware security module">Hardware security module</a></li><li><a href="/wiki/Semiconductor_device_fabrication" title="Semiconductor device fabrication">Semiconductor device fabrication</a></li><li><a href="/wiki/Tick%E2%80%93tock_model" title="Tick–tock model">Tick–tock model</a></li></ul></div></td></tr></tbody></table></div><!-- NewPP limit reportParsed by mw1396Cached time: 20201201110344Cache expiry: 2592000Dynamic content: falseComplications: [vary‐revision‐sha1]CPU time usage: 0.328 secondsReal time usage: 0.459 secondsPreprocessor visited node count: 999/1000000Post‐expand include size: 101833/2097152 bytesTemplate argument size: 583/2097152 bytesHighest expansion depth: 13/40Expensive parser function count: 2/500Unstrip recursion depth: 1/20Unstrip post‐expand size: 17215/5000000 bytesLua time usage: 0.123/10.000 secondsLua memory usage: 3743491/52428800 bytesNumber of Wikibase entities loaded: 0/400--><!--Transclusion expansion time report (%,ms,calls,template)100.00%  294.817      1 -total 45.10%  132.967      1 Template:Reflist 38.32%  112.978      2 Template:Cite_book 21.95%   64.722      7 Template:Navbox 14.02%   41.338      1 Template:Redirect-distinguish 12.77%   37.635      1 Template:Parallel_computing  9.82%   28.949      1 Template:As_of  9.24%   27.227      1 Template:CPU_technologies  5.43%   16.012      1 Template:Category-inline  5.36%   15.792      1 Template:DMCA--><!-- Saved in parser cache with key enwiki:pcache:idhash:58205-0!canonical!math=5 and timestamp 20201201110343 and revision id 991699793. Serialized with JSON. --></div><noscript><img src="//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1" alt="" title="" width="1" height="1" style="border: none; position: absolute;" /></noscript><div class="printfooter">Retrieved from "<a dir="ltr" href="https://en.wikipedia.org/w/index.php?title=Vector_processor&amp;oldid=991699793">https://en.wikipedia.org/w/index.php?title=Vector_processor&amp;oldid=991699793</a>"</div></div>		<div id="catlinks" class="catlinks" data-mw="interface"><div id="mw-normal-catlinks" class="mw-normal-catlinks"><a href="/wiki/Help:Category" title="Help:Category">Categories</a>: <ul><li><a href="/wiki/Category:Central_processing_unit" title="Category:Central processing unit">Central processing unit</a></li><li><a href="/wiki/Category:Coprocessors" title="Category:Coprocessors">Coprocessors</a></li><li><a href="/wiki/Category:Parallel_computing" title="Category:Parallel computing">Parallel computing</a></li><li><a href="/wiki/Category:Vector_supercomputers" title="Category:Vector supercomputers">Vector supercomputers</a></li></ul></div><div id="mw-hidden-catlinks" class="mw-hidden-catlinks mw-hidden-cats-hidden">Hidden categories: <ul><li><a href="/wiki/Category:Articles_containing_potentially_dated_statements_from_2016" title="Category:Articles containing potentially dated statements from 2016">Articles containing potentially dated statements from 2016</a></li><li><a href="/wiki/Category:All_articles_containing_potentially_dated_statements" title="Category:All articles containing potentially dated statements">All articles containing potentially dated statements</a></li></ul></div></div>	</div></div><div id='mw-data-after-content'>	<div class="read-more-container"></div></div><div id="mw-navigation">	<h2>Navigation menu</h2>	<div id="mw-head">		<!-- Please do not use role attribute as CSS selector, it is deprecated. --><nav id="p-personal" class="mw-portlet mw-portlet-personal vector-menu" aria-labelledby="p-personal-label" role="navigation" 	 >	<h3 id="p-personal-label">		<span>Personal tools</span>	</h3>	<div class="vector-menu-content">		<ul class="vector-menu-content-list"><li id="pt-anonuserpage">Not logged in</li><li id="pt-anontalk"><a href="/wiki/Special:MyTalk" title="Discussion about edits from this IP address [n]" accesskey="n">Talk</a></li><li id="pt-anoncontribs"><a href="/wiki/Special:MyContributions" title="A list of edits made from this IP address [y]" accesskey="y">Contributions</a></li><li id="pt-createaccount"><a href="/w/index.php?title=Special:CreateAccount&amp;returnto=Vector+processor" title="You are encouraged to create an account and log in; however, it is not mandatory">Create account</a></li><li id="pt-login"><a href="/w/index.php?title=Special:UserLogin&amp;returnto=Vector+processor" title="You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]" accesskey="o">Log in</a></li></ul>			</div></nav>		<div id="left-navigation">			<!-- Please do not use role attribute as CSS selector, it is deprecated. --><nav id="p-namespaces" class="mw-portlet mw-portlet-namespaces vector-menu vector-menu-tabs" aria-labelledby="p-namespaces-label" role="navigation" 	 >	<h3 id="p-namespaces-label">		<span>Namespaces</span>	</h3>	<div class="vector-menu-content">		<ul class="vector-menu-content-list"><li id="ca-nstab-main" class="selected"><a href="/wiki/Vector_processor" title="View the content page [c]" accesskey="c">Article</a></li><li id="ca-talk"><a href="/wiki/Talk:Vector_processor" rel="discussion" title="Discuss improvements to the content page [t]" accesskey="t">Talk</a></li></ul>			</div></nav>			<!-- Please do not use role attribute as CSS selector, it is deprecated. --><nav id="p-variants" class="mw-portlet mw-portlet-variants emptyPortlet vector-menu vector-menu-dropdown" aria-labelledby="p-variants-label" role="navigation" 	 >	<input type="checkbox" class="vector-menu-checkbox" aria-labelledby="p-variants-label" />	<h3 id="p-variants-label">		<span>Variants</span>	</h3>	<div class="vector-menu-content">		<ul class="vector-menu-content-list"></ul>			</div></nav>		</div>		<div id="right-navigation">			<!-- Please do not use role attribute as CSS selector, it is deprecated. --><nav id="p-views" class="mw-portlet mw-portlet-views vector-menu vector-menu-tabs" aria-labelledby="p-views-label" role="navigation" 	 >	<h3 id="p-views-label">		<span>Views</span>	</h3>	<div class="vector-menu-content">		<ul class="vector-menu-content-list"><li id="ca-view" class="selected"><a href="/wiki/Vector_processor">Read</a></li><li id="ca-edit"><a href="/w/index.php?title=Vector_processor&amp;action=edit" title="Edit this page [e]" accesskey="e">Edit</a></li><li id="ca-history"><a href="/w/index.php?title=Vector_processor&amp;action=history" title="Past revisions of this page [h]" accesskey="h">View history</a></li></ul>			</div></nav>			<!-- Please do not use role attribute as CSS selector, it is deprecated. --><nav id="p-cactions" class="mw-portlet mw-portlet-cactions emptyPortlet vector-menu vector-menu-dropdown" aria-labelledby="p-cactions-label" role="navigation" 	 >	<input type="checkbox" class="vector-menu-checkbox" aria-labelledby="p-cactions-label" />	<h3 id="p-cactions-label">		<span>More</span>	</h3>	<div class="vector-menu-content">		<ul class="vector-menu-content-list"></ul>			</div></nav>			<div id="p-search" role="search">	<h3 >		<label for="searchInput">Search</label>	</h3>	<form action="/w/index.php" id="searchform">		<div id="simpleSearch" data-search-loc="header-navigation">			<input type="search" name="search" placeholder="Search Wikipedia" autocapitalize="sentences" title="Search Wikipedia [f]" accesskey="f" id="searchInput"/>			<input type="hidden" name="title" value="Special:Search">			<input type="submit" name="fulltext" value="Search" title="Search Wikipedia for this text" id="mw-searchButton" class="searchButton mw-fallbackSearchButton"/>			<input type="submit" name="go" value="Go" title="Go to a page with this exact name if it exists" id="searchButton" class="searchButton"/>		</div>	</form></div>		</div>	</div>	<div id="mw-panel">	<div id="p-logo" role="banner">		<a  title="Visit the main page" class="mw-wiki-logo" href="/wiki/Main_Page"></a>	</div>	<!-- Please do not use role attribute as CSS selector, it is deprecated. --><nav id="p-navigation" class="mw-portlet mw-portlet-navigation vector-menu vector-menu-portal portal portal-first" aria-labelledby="p-navigation-label" role="navigation" 	 >	<h3 id="p-navigation-label">		<span>Navigation</span>	</h3>	<div class="vector-menu-content">		<ul class="vector-menu-content-list"><li id="n-mainpage-description"><a href="/wiki/Main_Page" title="Visit the main page [z]" accesskey="z">Main page</a></li><li id="n-contents"><a href="/wiki/Wikipedia:Contents" title="Guides to browsing Wikipedia">Contents</a></li><li id="n-currentevents"><a href="/wiki/Portal:Current_events" title="Articles related to current events">Current events</a></li><li id="n-randompage"><a href="/wiki/Special:Random" title="Visit a randomly selected article [x]" accesskey="x">Random article</a></li><li id="n-aboutsite"><a href="/wiki/Wikipedia:About" title="Learn about Wikipedia and how it works">About Wikipedia</a></li><li id="n-contactpage"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us" title="How to contact Wikipedia">Contact us</a></li><li id="n-sitesupport"><a href="https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en" title="Support us by donating to the Wikimedia Foundation">Donate</a></li></ul>			</div></nav>	<!-- Please do not use role attribute as CSS selector, it is deprecated. --><nav id="p-interaction" class="mw-portlet mw-portlet-interaction vector-menu vector-menu-portal portal" aria-labelledby="p-interaction-label" role="navigation" 	 >	<h3 id="p-interaction-label">		<span>Contribute</span>	</h3>	<div class="vector-menu-content">		<ul class="vector-menu-content-list"><li id="n-help"><a href="/wiki/Help:Contents" title="Guidance on how to use and edit Wikipedia">Help</a></li><li id="n-introduction"><a href="/wiki/Help:Introduction" title="Learn how to edit Wikipedia">Learn to edit</a></li><li id="n-portal"><a href="/wiki/Wikipedia:Community_portal" title="The hub for editors">Community portal</a></li><li id="n-recentchanges"><a href="/wiki/Special:RecentChanges" title="A list of recent changes to Wikipedia [r]" accesskey="r">Recent changes</a></li><li id="n-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Add images or other media for use on Wikipedia">Upload file</a></li></ul>			</div></nav><!-- Please do not use role attribute as CSS selector, it is deprecated. --><nav id="p-tb" class="mw-portlet mw-portlet-tb vector-menu vector-menu-portal portal" aria-labelledby="p-tb-label" role="navigation" 	 >	<h3 id="p-tb-label">		<span>Tools</span>	</h3>	<div class="vector-menu-content">		<ul class="vector-menu-content-list"><li id="t-whatlinkshere"><a href="/wiki/Special:WhatLinksHere/Vector_processor" title="List of all English Wikipedia pages containing links to this page [j]" accesskey="j">What links here</a></li><li id="t-recentchangeslinked"><a href="/wiki/Special:RecentChangesLinked/Vector_processor" rel="nofollow" title="Recent changes in pages linked from this page [k]" accesskey="k">Related changes</a></li><li id="t-upload"><a href="/wiki/Wikipedia:File_Upload_Wizard" title="Upload files [u]" accesskey="u">Upload file</a></li><li id="t-specialpages"><a href="/wiki/Special:SpecialPages" title="A list of all special pages [q]" accesskey="q">Special pages</a></li><li id="t-permalink"><a href="/w/index.php?title=Vector_processor&amp;oldid=991699793" title="Permanent link to this revision of this page">Permanent link</a></li><li id="t-info"><a href="/w/index.php?title=Vector_processor&amp;action=info" title="More information about this page">Page information</a></li><li id="t-cite"><a href="/w/index.php?title=Special:CiteThisPage&amp;page=Vector_processor&amp;id=991699793&amp;wpFormIdentifier=titleform" title="Information on how to cite this page">Cite this page</a></li><li id="t-wikibase"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q919509" title="Structured data on this page hosted by Wikidata [g]" accesskey="g">Wikidata item</a></li></ul>			</div></nav><!-- Please do not use role attribute as CSS selector, it is deprecated. --><nav id="p-coll-print_export" class="mw-portlet mw-portlet-coll-print_export vector-menu vector-menu-portal portal" aria-labelledby="p-coll-print_export-label" role="navigation" 	 >	<h3 id="p-coll-print_export-label">		<span>Print/export</span>	</h3>	<div class="vector-menu-content">		<ul class="vector-menu-content-list"><li id="coll-download-as-rl"><a href="/w/index.php?title=Special:DownloadAsPdf&amp;page=Vector_processor&amp;action=show-download-screen" title="Download this page as a PDF file">Download as PDF</a></li><li id="t-print"><a href="/w/index.php?title=Vector_processor&amp;printable=yes" title="Printable version of this page [p]" accesskey="p">Printable version</a></li></ul>			</div></nav>	<!-- Please do not use role attribute as CSS selector, it is deprecated. --><nav id="p-lang" class="mw-portlet mw-portlet-lang vector-menu vector-menu-portal portal" aria-labelledby="p-lang-label" role="navigation" 	 >	<h3 id="p-lang-label">		<span>Languages</span>	</h3>	<div class="vector-menu-content">		<ul class="vector-menu-content-list"><li class="interlanguage-link interwiki-ar"><a href="https://ar.wikipedia.org/wiki/%D9%85%D8%B9%D8%A7%D9%84%D8%AC_%D8%B4%D8%B9%D8%A7%D8%B9%D9%8A" title="معالج شعاعي – Arabic" lang="ar" hreflang="ar" class="interlanguage-link-target">العربية</a></li><li class="interlanguage-link interwiki-az"><a href="https://az.wikipedia.org/wiki/Vektor_prosessoru" title="Vektor prosessoru – Azerbaijani" lang="az" hreflang="az" class="interlanguage-link-target">Azərbaycanca</a></li><li class="interlanguage-link interwiki-ca"><a href="https://ca.wikipedia.org/wiki/Processador_vectorial" title="Processador vectorial – Catalan" lang="ca" hreflang="ca" class="interlanguage-link-target">Català</a></li><li class="interlanguage-link interwiki-cs"><a href="https://cs.wikipedia.org/wiki/Vektorov%C3%BD_procesor" title="Vektorový procesor – Czech" lang="cs" hreflang="cs" class="interlanguage-link-target">Čeština</a></li><li class="interlanguage-link interwiki-de"><a href="https://de.wikipedia.org/wiki/Vektorprozessor" title="Vektorprozessor – German" lang="de" hreflang="de" class="interlanguage-link-target">Deutsch</a></li><li class="interlanguage-link interwiki-es"><a href="https://es.wikipedia.org/wiki/Procesador_vectorial" title="Procesador vectorial – Spanish" lang="es" hreflang="es" class="interlanguage-link-target">Español</a></li><li class="interlanguage-link interwiki-fa"><a href="https://fa.wikipedia.org/wiki/%D9%BE%D8%B1%D8%AF%D8%A7%D8%B2%D9%86%D8%AF%D9%87_%D8%A8%D8%B1%D8%AF%D8%A7%D8%B1%DB%8C" title="پردازنده برداری – Persian" lang="fa" hreflang="fa" class="interlanguage-link-target">فارسی</a></li><li class="interlanguage-link interwiki-fr"><a href="https://fr.wikipedia.org/wiki/Processeur_vectoriel" title="Processeur vectoriel – French" lang="fr" hreflang="fr" class="interlanguage-link-target">Français</a></li><li class="interlanguage-link interwiki-ga"><a href="https://ga.wikipedia.org/wiki/Pr%C3%B3ise%C3%A1la%C3%AD_eagar" title="Próiseálaí eagar – Irish" lang="ga" hreflang="ga" class="interlanguage-link-target">Gaeilge</a></li><li class="interlanguage-link interwiki-ko"><a href="https://ko.wikipedia.org/wiki/%EB%B2%A1%ED%84%B0_%ED%94%84%EB%A1%9C%EC%84%B8%EC%84%9C" title="벡터 프로세서 – Korean" lang="ko" hreflang="ko" class="interlanguage-link-target">한국어</a></li><li class="interlanguage-link interwiki-id"><a href="https://id.wikipedia.org/wiki/Prosesor_vektor" title="Prosesor vektor – Indonesian" lang="id" hreflang="id" class="interlanguage-link-target">Bahasa Indonesia</a></li><li class="interlanguage-link interwiki-it"><a href="https://it.wikipedia.org/wiki/Processore_vettoriale" title="Processore vettoriale – Italian" lang="it" hreflang="it" class="interlanguage-link-target">Italiano</a></li><li class="interlanguage-link interwiki-hu"><a href="https://hu.wikipedia.org/wiki/Vektorprocesszor" title="Vektorprocesszor – Hungarian" lang="hu" hreflang="hu" class="interlanguage-link-target">Magyar</a></li><li class="interlanguage-link interwiki-nl"><a href="https://nl.wikipedia.org/wiki/Array_processor" title="Array processor – Dutch" lang="nl" hreflang="nl" class="interlanguage-link-target">Nederlands</a></li><li class="interlanguage-link interwiki-ja"><a href="https://ja.wikipedia.org/wiki/%E3%83%99%E3%82%AF%E3%83%88%E3%83%AB%E8%A8%88%E7%AE%97%E6%A9%9F" title="ベクトル計算機 – Japanese" lang="ja" hreflang="ja" class="interlanguage-link-target">日本語</a></li><li class="interlanguage-link interwiki-no"><a href="https://no.wikipedia.org/wiki/Vektorprosessor" title="Vektorprosessor – Norwegian Bokmål" lang="nb" hreflang="nb" class="interlanguage-link-target">Norsk bokmål</a></li><li class="interlanguage-link interwiki-pl"><a href="https://pl.wikipedia.org/wiki/Procesor_wektorowy" title="Procesor wektorowy – Polish" lang="pl" hreflang="pl" class="interlanguage-link-target">Polski</a></li><li class="interlanguage-link interwiki-pt"><a href="https://pt.wikipedia.org/wiki/Processador_vetorial" title="Processador vetorial – Portuguese" lang="pt" hreflang="pt" class="interlanguage-link-target">Português</a></li><li class="interlanguage-link interwiki-ro"><a href="https://ro.wikipedia.org/wiki/Procesor_vectorial" title="Procesor vectorial – Romanian" lang="ro" hreflang="ro" class="interlanguage-link-target">Română</a></li><li class="interlanguage-link interwiki-ru"><a href="https://ru.wikipedia.org/wiki/%D0%92%D0%B5%D0%BA%D1%82%D0%BE%D1%80%D0%BD%D1%8B%D0%B9_%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81%D0%BE%D1%80" title="Векторный процессор – Russian" lang="ru" hreflang="ru" class="interlanguage-link-target">Русский</a></li><li class="interlanguage-link interwiki-sk"><a href="https://sk.wikipedia.org/wiki/Vektorov%C3%BD_procesor" title="Vektorový procesor – Slovak" lang="sk" hreflang="sk" class="interlanguage-link-target">Slovenčina</a></li><li class="interlanguage-link interwiki-fi"><a href="https://fi.wikipedia.org/wiki/Vektorisuoritin" title="Vektorisuoritin – Finnish" lang="fi" hreflang="fi" class="interlanguage-link-target">Suomi</a></li><li class="interlanguage-link interwiki-uk"><a href="https://uk.wikipedia.org/wiki/%D0%92%D0%B5%D0%BA%D1%82%D0%BE%D1%80%D0%BD%D0%B8%D0%B9_%D0%BF%D1%80%D0%BE%D1%86%D0%B5%D1%81%D0%BE%D1%80" title="Векторний процесор – Ukrainian" lang="uk" hreflang="uk" class="interlanguage-link-target">Українська</a></li><li class="interlanguage-link interwiki-zh"><a href="https://zh.wikipedia.org/wiki/%E5%90%91%E9%87%8F%E5%A4%84%E7%90%86%E5%99%A8" title="向量处理器 – Chinese" lang="zh" hreflang="zh" class="interlanguage-link-target">中文</a></li></ul>		<div class="after-portlet after-portlet-lang"><span class="wb-langlinks-edit wb-langlinks-link"><a href="https://www.wikidata.org/wiki/Special:EntityPage/Q919509#sitelinks-wikipedia" title="Edit interlanguage links" class="wbc-editpage">Edit links</a></span></div>	</div></nav></div></div><footer id="footer" class="mw-footer" role="contentinfo" >	<ul id="footer-info" >	<li id="footer-info-lastmod"> This page was last edited on 1 December 2020, at 11:03<span class="anonymous-show">&#160;(UTC)</span>.</li>	<li id="footer-info-copyright">Text is available under the <a rel="license" href="//en.wikipedia.org/wiki/Wikipedia:Text_of_Creative_Commons_Attribution-ShareAlike_3.0_Unported_License">Creative Commons Attribution-ShareAlike License</a><a rel="license" href="//creativecommons.org/licenses/by-sa/3.0/" style="display:none;"></a>;additional terms may apply.  By using this site, you agree to the <a href="//foundation.wikimedia.org/wiki/Terms_of_Use">Terms of Use</a> and <a href="//foundation.wikimedia.org/wiki/Privacy_policy">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href="//www.wikimediafoundation.org/">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li></ul>	<ul id="footer-places" >	<li id="footer-places-privacy"><a href="https://foundation.wikimedia.org/wiki/Privacy_policy" class="extiw" title="wmf:Privacy policy">Privacy policy</a></li>	<li id="footer-places-about"><a href="/wiki/Wikipedia:About" title="Wikipedia:About">About Wikipedia</a></li>	<li id="footer-places-disclaimer"><a href="/wiki/Wikipedia:General_disclaimer" title="Wikipedia:General disclaimer">Disclaimers</a></li>	<li id="footer-places-contact"><a href="//en.wikipedia.org/wiki/Wikipedia:Contact_us">Contact Wikipedia</a></li>	<li id="footer-places-mobileview"><a href="//en.m.wikipedia.org/w/index.php?title=Vector_processor&amp;mobileaction=toggle_view_mobile" class="noprint stopMobileRedirectToggle">Mobile view</a></li>	<li id="footer-places-developers"><a href="https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute">Developers</a></li>	<li id="footer-places-statslink"><a href="https://stats.wikimedia.org/#/en.wikipedia.org">Statistics</a></li>	<li id="footer-places-cookiestatement"><a href="https://foundation.wikimedia.org/wiki/Cookie_statement">Cookie statement</a></li></ul>	<ul id="footer-icons" class="noprint">	<li id="footer-copyrightico"><a href="https://wikimediafoundation.org/"><img src="/static/images/footer/wikimedia-button.png" srcset="/static/images/footer/wikimedia-button-1.5x.png 1.5x, /static/images/footer/wikimedia-button-2x.png 2x" width="88" height="31" alt="Wikimedia Foundation" loading="lazy" /></a></li>	<li id="footer-poweredbyico"><a href="https://www.mediawiki.org/"><img src="/static/images/footer/poweredby_mediawiki_88x31.png" alt="Powered by MediaWiki" srcset="/static/images/footer/poweredby_mediawiki_132x47.png 1.5x, /static/images/footer/poweredby_mediawiki_176x62.png 2x" width="88" height="31" loading="lazy"/></a></li></ul>	<div style="clear: both;"></div></footer><script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgPageParseReport":{"limitreport":{"cputime":"0.328","walltime":"0.459","ppvisitednodes":{"value":999,"limit":1000000},"postexpandincludesize":{"value":101833,"limit":2097152},"templateargumentsize":{"value":583,"limit":2097152},"expansiondepth":{"value":13,"limit":40},"expensivefunctioncount":{"value":2,"limit":500},"unstrip-depth":{"value":1,"limit":20},"unstrip-size":{"value":17215,"limit":5000000},"entityaccesscount":{"value":0,"limit":400},"timingprofile":["100.00%  294.817      1 -total"," 45.10%  132.967      1 Template:Reflist"," 38.32%  112.978      2 Template:Cite_book"," 21.95%   64.722      7 Template:Navbox"," 14.02%   41.338      1 Template:Redirect-distinguish"," 12.77%   37.635      1 Template:Parallel_computing","  9.82%   28.949      1 Template:As_of","  9.24%   27.227      1 Template:CPU_technologies","  5.43%   16.012      1 Template:Category-inline","  5.36%   15.792      1 Template:DMCA"]},"scribunto":{"limitreport-timeusage":{"value":"0.123","limit":"10.000"},"limitreport-memusage":{"value":3743491,"limit":52428800}},"cachereport":{"origin":"mw1396","timestamp":"20201201110344","ttl":2592000,"transientcontent":false}}});});</script><script type="application/ld+json">{"@context":"https:\/\/schema.org","@type":"Article","name":"Vector processor","url":"https:\/\/en.wikipedia.org\/wiki\/Vector_processor","sameAs":"http:\/\/www.wikidata.org\/entity\/Q919509","mainEntity":"http:\/\/www.wikidata.org\/entity\/Q919509","author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https:\/\/www.wikimedia.org\/static\/images\/wmf-hor-googpub.png"}},"datePublished":"2002-06-19T15:16:34Z","dateModified":"2020-12-01T11:03:37Z","headline":"computer processor which works on arrays of several numbers at once"}</script><script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({"wgBackendResponseTime":130,"wgHostname":"mw1391"});});</script></body></html>