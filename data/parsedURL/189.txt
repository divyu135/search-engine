Context-sensitive grammar - Wikipedia Context-sensitive grammar From Wikipedia, the free encyclopedia Jump to navigation Jump to search A context-sensitive grammar (CSG) is a formal grammar in which the left-hand sides and right-hand sides of any production rules may be surrounded by a context of terminal and nonterminal symbols. Context-sensitive grammars are more general than context-free grammars, in the sense that there are languages that can be described by CSG but not by context-free grammars. Context-sensitive grammars are less general (in the same sense) than unrestricted grammars. Thus, CSG are positioned between context-free and unrestricted grammars in the Chomsky hierarchy. A formal language that can be described by a context-sensitive grammar, or, equivalently, by a noncontracting grammar or a linear bounded automaton, is called a context-sensitive language. Some textbooks actually define CSGs as non-contracting,[1][2][3][4] although this is not how Noam Chomsky defined them in 1959.[5][6] This choice of definition makes no difference in terms of the languages generated (i.e. the two definitions are weakly equivalent), but it does make a difference in terms of what grammars are structurally considered context-sensitive; the latter issue was analyzed by Chomsky in 1963.[7][8] Chomsky introduced context-sensitive grammars as a way to describe the syntax of natural language where it is often the case that a word may or may not be appropriate in a certain place depending on the context. Walter Savitch has criticized the terminology "context-sensitive" as misleading and proposed "non-erasing" as better explaining the distinction between a CSG and an unrestricted grammar.[9] Although it is well known that certain features of languages (e.g. cross-serial dependency) are not context-free, it is an open question how much of CSG's expressive power is needed to capture the context sensitivity found in natural languages. Subsequent research in this area has focused on the more computationally tractable mildly context-sensitive languages.[citation needed] The syntaxes of some visual programming languages can be described by context-sensitive graph grammars.[10] Contents 1 Formal definition 2 Examples 3 Kuroda normal form 4 Properties and uses 4.1 Equivalence to linear bounded automaton 4.2 Closure properties 4.3 Computational problems 4.4 As model of natural languages 5 See also 6 Notes 7 References 8 Further reading 9 External links Formal definition[edit] A formal grammar G = (N, Σ, P, S), where N is a set of nonterminal symbols, Σ is a set of terminal symbols, P is a set of production rules, and S is the start symbol, is context-sensitive if all rules in P are of the form αAβ → αγβ where A ∈ N,[note 1] α,β ∈ (N∪Σ)* [note 2] and γ ∈ (N∪Σ)+.[note 3] A string u ∈ (N∪Σ)* directly yields, or directly derives to, a string v ∈ (N∪Σ)*, denoted as u ⇒ v, if u can be written as lαAβr, and v can be written as lαγβr, for some production rule (αAβ→αγβ) ∈ P, and some context strings l, r ∈ (N∪Σ)*.More generally, u is said to yield, or derive to, v, denoted as u ⇒* v, if u = u1 ⇒ ... ⇒ un = v for some n≥0 and some strings u2, ..., un-1 (N∪Σ)*. That is, the relation (⇒*) is the reflexive transitive closure of the relation (⇒). The language of the grammar G is the set of all terminal symbol strings derivable from its start symbol, formally: L(G) = { w ∈ Σ*: S ⇒* w }.Derivations that do not end in a string composed of terminal symbols only are possible, but don't contribute to L(G). The only difference between this definition of Chomsky and that of unrestricted grammars is that γ can be empty in the unrestricted case.[9] Some definitions of a context-sensitive grammar only require that for any production rule of the form u → v, the length of u shall be less than or equal to the length of v. This seemingly weaker requirement is in fact weakly equivalent,[11] see Noncontracting grammar#Transforming into context-sensitive grammar. In addition, a rule of the form S → λ where λ represents the empty string and S does not appear on the right-hand side of any rule is permitted. The addition of the empty string allows the statement that the context sensitive languages are a proper superset of the context-free languages, rather than having to make the weaker statement that all context-free grammars with no →λ productions are also context sensitive grammars. The name context-sensitive is explained by the α and β that form the context of A and determine whether A can be replaced with γ or not. This is different from a context-free grammar where the context of a nonterminal is not taken into consideration. Indeed, every production of a context-free grammar is of the form V → w where V is a single nonterminal symbol, and w is a string of terminals and/or nonterminals; w can be empty. If the possibility of adding the empty string to a language is added to the strings recognized by the noncontracting grammars (which can never include the empty string) then the languages in these two definitions are identical. The left-context- and right-context-sensitive grammars are defined by restricting the rules to just the form αA → αγ and to just Aβ → γβ, respectively. The languages generated by these grammars are also the full class of context-sensitive languages.[12] The equivalence was established by Penttonen normal form.[13] Examples[edit] The following context-sensitive grammar, with start symbol S, generates the canonical non-context-free language { anbncn : n ≥ 1 } : 1. S → a B C 2. S → a S B C 3. C B → C Z 4. C Z → W Z 5. W Z → W C 6. W C → B C 7. a B → a b 8. b B → b b 9. b C → b c 10. c C → c c Rules 1 and 2 allow for blowing-up S to anBC(BC)n-1; rules 3 to 6 allow for successively exchanging each CB to BC (four rules are needed for that since a rule CB → BC wouldn't fit into the scheme αAβ → αγβ); rules 7–10 allow replacing a non-terminals B and C with its corresponding terminals b and c respectively, provided it is in the right place.A generation chain for aaabbbccc is: S →2 aSBC →2 aaSBCBC →1 aaaBCBCBC →3 aaaBCZCBC →4 aaaBWZCBC →5 aaaBWCCBC →6 aaaBBCCBC →3 aaaBBCCZC →4 aaaBBCWZC →5 aaaBBCWCC →6 aaaBBCBCC →3 aaaBBCZCC →4 aaaBBWZCC →5 aaaBBWCCC →6 aaaBBBCCC →7 aaabBBCCC →8 aaabbBCCC →8 aaabbbCCC →9 aaabbbcCC →10 aaabbbccC →10 aaabbbccc More complicated grammars C S G {\displaystyle CSG} can be used to parse { anbncndn: n ≥ 1 }, and other languages with even more letters. Here we show a simpler approach using non-contracting grammars:Start with a kernel of regular productions generating the sentential forms ( A B C D ) n a b c d {\displaystyle (ABCD)^{n}abcd} and then include the non contracting productions p D a : D a → a D {\displaystyle p_{Da}:Da\rightarrow aD} , p D b : D b → b D {\displaystyle p_{Db}:Db\rightarrow bD} , p D c : D c → c D {\displaystyle p_{Dc}:Dc\rightarrow cD} , p D d : D d → d d {\displaystyle p_{Dd}:Dd\rightarrow dd} , p C a : C a → a C {\displaystyle p_{Ca}:Ca\rightarrow aC} , p C b : C b → b C {\displaystyle p_{Cb}:Cb\rightarrow bC} , p C c : C c → c c {\displaystyle p_{Cc}:Cc\rightarrow cc} , p B a : B a → a B {\displaystyle p_{Ba}:Ba\rightarrow aB} , p B b : B b → b b {\displaystyle p_{Bb}:Bb\rightarrow bb} , p A a : A a → a a {\displaystyle p_{Aa}:Aa\rightarrow aa} . A non contracting grammar (for which there is an equivalent C S G {\displaystyle CSG} ) for the language L C r o s s = { a m b n c m d n : m ≥ 1 , n ≥ 1 } {\displaystyle L_{Cross}=\{a^{m}b^{n}c^{m}d^{n}:m\geq 1,n\geq 1\}} is defined by p 1 : R → a R C | a C {\displaystyle p_{1}:R\rightarrow aRC|aC} and p 3 : T → B T d | B d {\displaystyle p_{3}:T\rightarrow BTd|Bd} , p 5 : C B → B C {\displaystyle p_{5}:CB\rightarrow BC} , p 0 : S → R T {\displaystyle p_{0}:S\rightarrow RT} , p 6 : a B → a b {\displaystyle p_{6}:aB\rightarrow ab} , p 7 : b B → b b {\displaystyle p_{7}:bB\rightarrow bb} , p 8 : C d → c d {\displaystyle p_{8}:Cd\rightarrow cd} , p 9 : C c → c c {\displaystyle p_{9}:Cc\rightarrow cc} . With these definitions, a derivation for a 3 b 2 c 3 d 2 {\displaystyle a^{3}b^{2}c^{3}d^{2}} is: S ⇒ p 0 R T ⇒ p 1 2 p 2 a 3 C 3 T ⇒ p 3 p 4 a 3 C 3 B 2 d 2 ⇒ p 5 6 a 3 B 2 C 3 d 2 ⇒ p 6 p 7 a 3 b 2 C 3 d 2 ⇒ p 8 p 9 2 a 3 b 2 c 3 d 2 {\displaystyle S\Rightarrow _{p_{0}}RT\Rightarrow _{p_{1}^{2}p_{2}}a^{3}C^{3}T\Rightarrow _{p_{3}p_{4}}a^{3}C^{3}B^{2}d^{2}\Rightarrow _{p_{5}^{6}}a^{3}B^{2}C^{3}d^{2}\Rightarrow _{p_{6}p_{7}}a^{3}b^{2}C^{3}d^{2}\Rightarrow _{p_{8}p_{9}^{2}}a^{3}b^{2}c^{3}d^{2}} .[citation needed] A noncontracting grammar for the language { a2i : i ≥ 1 } is constructed in Example 9.5 (p. 224) of (Hopcroft, Ullman, 1979):[14] S → [ A C a B ] {\displaystyle S\rightarrow [ACaB]} { [ C a ] a → a a [ C a ] [ C a ] [ a B ] → a a [ C a B ] [ A C a ] a → [ A a ] a [ C a ] [ A C a ] [ a B ] → [ A a ] a [ C a B ] [ A C a B ] → [ A a ] [ a C B ] [ C a B ] → a [ a C B ] {\displaystyle {\begin{cases}\ [Ca]a\rightarrow aa[Ca]\\\ [Ca][aB]\rightarrow aa[CaB]\\\ [ACa]a\rightarrow [Aa]a[Ca]\\\ [ACa][aB]\rightarrow [Aa]a[CaB]\\\ [ACaB]\rightarrow [Aa][aCB]\\\ [CaB]\rightarrow a[aCB]\end{cases}}} [ a C B ] → [ a D B ] {\displaystyle [aCB]\rightarrow [aDB]} [ a C B ] → [ a E ] {\displaystyle [aCB]\rightarrow [aE]} { a [ D a ] → [ D a ] a [ a D B ] → [ D a B ] [ A a ] [ D a ] → [ A D a ] a a [ D a B ] → [ D a ] [ a B ] [ A a ] [ D a B ] → [ A D a ] [ a B ] {\displaystyle {\begin{cases}\ a[Da]\rightarrow [Da]a\\\ [aDB]\rightarrow [DaB]\\\ [Aa][Da]\rightarrow [ADa]a\\\ a[DaB]\rightarrow [Da][aB]\\\ [Aa][DaB]\rightarrow [ADa][aB]\end{cases}}} [ A D a ] → [ A C a ] {\displaystyle [ADa]\rightarrow [ACa]} { a [ E a ] → [ E a ] a [ a E ] → [ E a ] [ A a ] [ E a ] → [ A E a ] a {\displaystyle {\begin{cases}\ a[Ea]\rightarrow [Ea]a\\\ [aE]\rightarrow [Ea]\\\ [Aa][Ea]\rightarrow [AEa]a\end{cases}}} [ A E a ] → a {\displaystyle [AEa]\rightarrow a} Kuroda normal form[edit] Every context-sensitive grammar which does not generate the empty string can be transformed into a weakly equivalent one in Kuroda normal form. "Weakly equivalent" here means that the two grammars generate the same language. The normal form will not in general be context-sensitive, but will be a noncontracting grammar.[15][16] The Kuroda normal form is an actual normal form for non-contracting grammars. Properties and uses[edit] See also: context-sensitive language This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed. (August 2014) (Learn how and when to remove this template message) Equivalence to linear bounded automaton[edit] A formal language can be described by a context-sensitive grammar if and only if it is accepted by some linear bounded automaton (LBA).[17] In some textbooks this result is attributed solely to Landweber and Kuroda.[6] Others call it the Myhill–Landweber–Kuroda theorem.[18] (Myhill introduced the concept of deterministic LBA in 1960. Peter S. Landweber published in 1963 that the language accepted by a deterministic LBA is context sensitive. Kuroda introduced the notion of non-deterministic LBA and the equivalence between LBA and CSGs in 1964.[19][20]) As of 2010[update] it is still an open question whether every context-sensitive language can be accepted by a deterministic LBA.[21] Closure properties[edit] Context-sensitive languages are closed under complement. This 1988 result is known as the Immerman–Szelepcsényi theorem.[18]Moreover, they are closed under union, intersection, concatenation, substitution,[note 4] inverse homomorphism, and Kleene plus.[22] Every recursively enumerable language L can be written as h(L) for some context-sensitive language L and some string homomorphism h.[23] Computational problems[edit] The decision problem that asks whether a certain string s belongs to the language of a given context-sensitive grammar G, is PSPACE-complete. Moreover, there are context-sensitive grammars whose languages are PSPACE-complete. In other words, there is a context-sensitive grammar G such that deciding whether a certain string s belongs to the language of G is PSPACE-complete (so G is fixed and only s is part of the input of the problem).[24] The emptiness problem for context-sensitive grammars (given a context-sensitive grammar G, is L(G)=∅ ?) is undecidable.[25][note 5] As model of natural languages[edit] Savitch has proven the following theoretical result, on which he bases his criticism of CSGs as basis for natural language: for any recursively enumerable set R, there exists a context-sensitive language/grammar G which can be used as a sort of proxy to test membership in R in the following way: given a string s, s is in R if and only if there exists a positive integer n for which scn is in G, where c is an arbitrary symbol not part of R.[9] It has been shown that nearly all natural languages may in general be characterized by context-sensitive grammars, but the whole class of CSG's seems to be much bigger than natural languages.[citation needed] Worse yet, since the aforementioned decision problem for CSG's is PSPACE-complete, that makes them totally unworkable for practical use, as a polynomial-time algorithm for a PSPACE-complete problem would imply P=NP. It was proven that some natural languages are not context-free, based on identifying so-called cross-serial dependencies and unbounded scrambling phenomena. However this does not necessarily imply that all the class CSG is necessary to capture "context sensitivity" in the colloquial sense of these terms in natural languages. For example, the strictly weaker (than CSG) linear context-free rewriting systems (LCFRS) can account for the phenomenon of cross-serial dependencies; one can write a LCFRS grammar for {anbncndn | n ≥ 1} for example.[26][27][28] Ongoing research on computational linguistics has focused on formulating other classes of languages that are "mildly context-sensitive" whose decision problems are feasible, such as tree-adjoining grammars, combinatory categorial grammars, coupled context-free languages, and linear context-free rewriting systems. The languages generated by these formalisms properly lie between the context-free and context-sensitive languages. More recently, the class PTIME has been identified with range concatenation grammars, which are now considered to be the most expressive of the mild-context sensitive languages.[28] See also[edit] Chomsky hierarchy Growing context-sensitive grammar Definite clause grammar#Non-context-free grammars List of parser generators for context-sensitive grammars Notes[edit] ^ i.e., A is a single nonterminal ^ i.e., α and β are strings of nonterminals and terminals ^ i.e., γ is a nonempty string of nonterminals and terminals ^ more formally: if L ⊆ Σ* is a context-sensitive language and f maps each a∈Σ to a context-sensitive language f(a), the f(L) is again a context-sensitive language ^ This also follows from (1) context-free languages being also context-sensitive, (2) context-sensitive language being closed under intersection, but (3) disjointness of context-free languages being undecidable. References[edit] ^ Linz, Peter (2011). An Introduction to Formal Languages and Automata. Jones & Bartlett Publishers. p. 291. ISBN 978-1-4496-1552-9. ^ Meduna, Alexander (2000). Automata and Languages: Theory and Applications. Springer Science & Business Media. p. 730. ISBN 978-1-85233-074-3. ^ Davis, Martin; Sigal, Ron; Weyuker, Elaine J. (1994). Computability, Complexity, and Languages: Fundamentals of Theoretical Computer Science (2nd ed.). Morgan Kaufmann. p. 189. ISBN 978-0-08-050246-5. ^ Martin, John C. (2010). Introduction to Languages and the Theory of Computation (4th ed.). New York, NY: McGraw-Hill. p. 277. ISBN 9780073191461. ^ Levelt, Willem J. M. (2008). An Introduction to the Theory of Formal Languages and Automata. John Benjamins Publishing. p. 26. ISBN 978-90-272-3250-2. ^ a b Davis, Martin; Sigal, Ron; Weyuker, Elaine J. (1994). Computability, Complexity, and Languages: Fundamentals of Theoretical Computer Science (2nd ed.). Morgan Kaufmann. pp. 330–331. ISBN 978-0-08-050246-5. ^ Chomsky, N. (1963). "Formal properties of grammar". In Luce, R. D.; Bush, R. R.; Galanter, E. (eds.). Handbook of Mathematical Psychology. New York: Wiley. pp. 360–363. ^ Levelt, Willem J. M. (2008). An Introduction to the Theory of Formal Languages and Automata. John Benjamins Publishing. pp. 125–126. ISBN 978-90-272-3250-2. ^ a b c Carlos Martín Vide, ed. (1999). Issues in Mathematical Linguistics: Workshop on Mathematical Linguistics, State College, Pa., April 1998. John Benjamins Publishing. pp. 186–187. ISBN 90-272-1556-1. ^ Zhang, Da-Qian, Kang Zhang, and Jiannong Cao. "A context-sensitive graph grammar formalism for the specification of visual languages." The Computer Journal 44.3 (2001): 186–200. ^ Hopcroft, John E.; Ullman, Jeffrey D. (1979). Introduction to Automata Theory, Languages, and Computation. Addison-Wesley. ; p. 223–224; Exercise 9, p. 230. In the 2003 edition, the chapter on CSG has been omitted. ^ Hazewinkel, Michiel (1989). Encyclopaedia of Mathematics. 4. Springer Science & Business Media. p. 297. ISBN 978-1-55608-003-6. also at https://www.encyclopediaofmath.org/index.php/Grammar,_context-sensitive ^ Ito, Masami; Kobayashi, Yūji; Shoji, Kunitaka (2010). Automata, Formal Languages and Algebraic Systems: Proceedings of AFLAS 2008, Kyoto, Japan, 20–22 September 2008. World Scientific. p. 183. ISBN 978-981-4317-60-3. citing Penttonen, Martti (Aug 1974). "One-sided and two-sided context in formal grammars". Information and Control. 25 (4): 371–392. doi:10.1016/S0019-9958(74)91049-3. ^ They obtained the grammar by systematic transformation of an unrestricted grammar, given in Exm. 9.4, viz.: S → A C a B {\displaystyle S\rightarrow ACaB} , C a → a a C {\displaystyle Ca\rightarrow aaC} , C B → D B {\displaystyle CB\rightarrow DB} , C B → E {\displaystyle CB\rightarrow E} , a D → D a {\displaystyle aD\rightarrow Da} , A D → A C {\displaystyle AD\rightarrow AC} , a E → E a {\displaystyle aE\rightarrow Ea} , A E → ε {\displaystyle AE\rightarrow \varepsilon } . In the context-sensitive grammar, a string enclosed in square brackets, like [ A C a B ] {\displaystyle [ACaB]} , is considered a single symbol (similar to e.g. <name-part> in Backus–Naur form). The symbol names are chosen to resemble the unrestricted grammar. Likewise, rule groups in the context-sensitive grammar are numbered by the unrestricted-grammar rule they originated from. ^ Kuroda, Sige-Yuki (June 1964). "Classes of languages and linear-bounded automata". Information and Control. 7 (2): 207–223. doi:10.1016/s0019-9958(64)90120-2. ^ Mateescu, Alexandru; Salomaa, Arto (1997). "Chapter 4: Aspects of Classical Language Theory". In Rozenberg, Grzegorz; Salomaa, Arto (eds.). Handbook of Formal Languages. Volume I: Word, language, grammar. Springer-Verlag. pp. 175–252. ISBN 3-540-61486-9. , Here: Theorem 2.2, p. 190 ^ (Hopcroft, Ullman, 1979); Theorem 9.5, 9.6, p. 225–226 ^ a b https://www.cs.cmu.edu/~flac/pdf/ContSens.pdf ^ Meduna, Alexander (2000). Automata and Languages: Theory and Applications. Springer Science & Business Media. p. 755. ISBN 978-1-85233-074-3. ^ Levelt, Willem J. M. (2008). An Introduction to the Theory of Formal Languages and Automata. John Benjamins Publishing. pp. 126–127. ISBN 978-90-272-3250-2. ^ Martin, John C. (2010). Introduction to Languages and the Theory of Computation (4th ed.). New York, NY: McGraw-Hill. p. 283. ISBN 9780073191461. ^ (Hopcroft, Ullman, 1979); Exercise S9.10, p. 230–231 ^ (Hopcroft, Ullman, 1979); Exercise S9.14, p. 230–232. h maps each symbol to itself or to the empty string. ^ An example of such a grammar, designed to solve the QSAT problem, is given in Lita, C. V. (2016-09-01). "On Complexity of the Detection Problem for Bounded Length Polymorphic Viruses". 2016 18th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC): 371–378. doi:10.1109/SYNASC.2016.064. ISBN 978-1-5090-5707-8. ^ (Hopcroft, Ullman, 1979); Exercise S9.13, p. 230–231 ^ Kallmeyer, Laura (2011). "Mildly Context-Sensitive Grammar Formalisms: Natural Languages are not Context-Free" (PDF). ^ Kallmeyer, Laura (2011). "Mildly Context-Sensitive Grammar Formalisms: Linear Context-Free Rewriting Systems" (PDF). ^ a b Kallmeyer, Laura (2010). Parsing Beyond Context-Free Grammars. Springer Science & Business Media. pp. 1–5. ISBN 978-3-642-14846-0. Further reading[edit] Meduna, Alexander; Švec, Martin (2005). Grammars with Context Conditions and Their Applications. John Wiley & Sons. ISBN 978-0-471-73655-4. External links[edit] Earley Parsing for Context-Sensitive Grammars v t e Automata theory: formal languages and formal grammars Chomsky hierarchy Grammars Languages Abstract machines Type-0 — Type-1 — — — — — Type-2 — — Type-3 — — Unrestricted (no common name) Context-sensitive Positive range concatenation Indexed — Linear context-free rewriting systems Tree-adjoining Context-free Deterministic context-free Visibly pushdown Regular — Non-recursive Recursively enumerable Decidable Context-sensitive Positive range concatenation* Indexed* — Linear context-free rewriting language Tree-adjoining Context-free Deterministic context-free Visibly pushdown Regular Star-free Finite Turing machine Decider Linear-bounded PTIME Turing Machine Nested stack Thread automaton restricted Tree stack automaton Embedded pushdown Nondeterministic pushdown Deterministic pushdown Visibly pushdown Finite Counter-free (with aperiodic finite monoid) Acyclic finite Each category of languages, except those marked by a *, is a proper subset of the category directly above it. Any language in each category is generated by a grammar and by an automaton in the category in the same line. Retrieved from "https://en.wikipedia.org/w/index.php?title=Context-sensitive_grammar&oldid=991153774" Categories: Formal languages Grammar frameworks Hidden categories: All articles with unsourced statements Articles with unsourced statements from March 2018 Articles with unsourced statements from November 2018 Articles needing additional references from August 2014 All articles needing additional references Articles containing potentially dated statements from 2010 All articles containing potentially dated statements Articles with unsourced statements from November 2011 Navigation menu Personal tools Not logged in Talk Contributions Create account Log in Namespaces Article Talk Variants Views Read Edit View history More Search Navigation Main page Contents Current events Random article About Wikipedia Contact us Donate Contribute Help Learn to edit Community portal Recent changes Upload file Tools What links here Related changes Upload file Special pages Permanent link Page information Cite this page Wikidata item Print/export Download as PDF Printable version Languages Català Čeština Deutsch Español فارسی Français 한국어 Hrvatski Italiano עברית Nederlands 日本語 Polski Português Русский Slovenčina Српски / srpski Srpskohrvatski / српскохрватски Українська 中文 Edit links This page was last edited on 28 November 2020, at 15:40 (UTC). Text is available under the Creative Commons Attribution-ShareAlike License;additional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization. Privacy policy About Wikipedia Disclaimers Contact Wikipedia Mobile view Developers Statistics Cookie statement